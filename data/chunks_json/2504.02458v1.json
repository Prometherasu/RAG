[
  {
    "chunk_id": 0,
    "content": "## **Retrieval-Augmented Purifier for Robust** **LLM-Empowered Recommendation**\n\n**Liangbo Ning** **Wenqi Fan** *[∗]* **Qing Li**\nThe Hong Kong Polytechnic University, Hong Kong SAR, China\n`{BigLemon1123,wenqifan03}@gmail.com`, `qing-prof.li@polyu.edu.hk`\n### **Abstract**",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 1,
    "content": "Recently, Large Language Model (LLM)-empowered recommender systems have\nrevolutionized personalized recommendation frameworks and attracted extensive\nattention. Despite the remarkable success, existing LLM-empowered RecSys have",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 2,
    "content": "been demonstrated to be highly vulnerable to minor perturbations. To mitigate\nthe negative impact of such vulnerabilities, one potential solution is to employ\ncollaborative signals based on item-item co-occurrence to purify the malicious",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 3,
    "content": "collaborative knowledge from the user’s historical interactions inserted by attackers.\nOn the other hand, due to the capabilities to expand insufficient internal knowledge",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 4,
    "content": "of LLMs, Retrieval-Augmented Generation (RAG) techniques provide unprecedented opportunities to enhance the robustness of LLM-empowered recommender\nsystems by introducing external collaborative knowledge. Therefore, in this paper,",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 5,
    "content": "we propose a novel framework ( **RETURN** ) by retrieving external collaborative\nsignals to purify the poisoned user profiles and enhance the robustness of LLMempowered RecSys in a plug-and-play manner. Specifically, retrieval-augmented",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 6,
    "content": "perturbation positioning is proposed to identify potential perturbations within the\nusers’ historical sequences by retrieving external knowledge from collaborative\nitem graphs. After that, we further retrieve the collaborative knowledge to cleanse",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 7,
    "content": "the perturbations by using either deletion or replacement strategies and introduce\na robust ensemble recommendation strategy to generate final robust predictions.\nExtensive experiments on three real-world datasets demonstrate the effectiveness\nof the proposed RETURN.\n### **1 Introduction**",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 8,
    "content": "In today’s era of information explosion, recommender systems play a vital role in enhancing user\nexperiences and influencing user decisions by filtering out irrelevant information in various applications such as streaming platforms (e.g., YouTube [ 9, 10 ], TikTok [ 38, 5 ]) and e-commerce (e.g.,",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 9,
    "content": "Amazon [ 24 ], Taobao [ 48 ]). Technically, most existing representative recommendation methods\naim to capture collaborative signals by modeling user-item interactions [ 13, 12, 21 ]. Recently, large",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 10,
    "content": "language models (LLMs) have been widely applied in real-life scenarios due to their powerful capabilities in language comprehension and generation, and rich store of open-world knowledge [ 51, 77, 44 ].\nFor example, as one of the most famous AI chatbots in recent years, ChatGPT [ 1 ] has showcased",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 11,
    "content": "human-level intelligence with impressive logical reasoning, open-ended conversation, and personalized content recommendation abilities. To fully leverage the powerful capabilities of large language\nmodels, a significant amount of research has utilized LLMs to revolutionize recommender systems",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 12,
    "content": "for next-generation RecSys [ 50, 77, 35, 62 ]. For instance, Geng et al. [18] propose P5, which unifies\nvarious recommendation tasks by converting user-item interactions to natural language sequences,",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 13,
    "content": "*∗* Corresponding author: Wenqi Fan, Department of Computing, and Department of Management and\nMarketing, The Hong Kong Polytechnic University.\n\nPreprint. Under review.\n\n\n-----\n\n**User**\n\n\n**User**",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 14,
    "content": "Figure 1: The illustration of the robust LLM-empowered RecSys by introducing an external database\n(i.e., collaborative item graph). The minor perturbations (e.g., item ‘ *Ties* ’) in the user’s historical",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 15,
    "content": "sequence (i.e., adversarial prompt) can mislead LLM-empowered recommender systems to understand\nthe user’s preference. With the help of the external data source, LLM-empowered recommender\nsystems can identify the irrelevant item ‘ *Ties* ’ by retrieving relevant collaborative signals (i.e.,",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 16,
    "content": "retrieved subgraphs) from the collaborative item graphs, so as to purify the perturbations for the\nrobust recommendation.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 17,
    "content": "achieving outstanding recommendation performance due to the rich textual information that can help\ncapture complex semantics for personalization and recommendations.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 18,
    "content": "Despite the remarkable success, most existing LLM-empowered RecSys still encounter a key limitation, in which they have been demonstrated to be highly vulnerable to minor perturbations in the\ninput prompt [ 45 ], greatly constraining their practical applicability. Suppose that attackers might",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 19,
    "content": "post products with enticing images and titles to attract user clicks on an e-commerce platform. Users\nare easily drawn to these clickbait products and interact with them, even though the content of these",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 20,
    "content": "goods may not truly align with their preferences [ 61 ]. Such minor perturbations (e.g., irrelevant items)\ncan easily lead the LLM-empowered RecSys to misunderstand the user preferences by capturing\nthe collaborative knowledge from the user’s historical interactions towards items. For example, as",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 21,
    "content": "illustrated in Figure 1, when perturbation item \"ties\" is inserted into the user’s interaction sequence,\nthe perturbed collaborative knowledge makes LLM-empowered RecSys struggle to discern whether\nthe user is seeking men’s clothing (i.e., \"suits\") or women’s clothing (i.e., \"dresses\"), leading to",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 22,
    "content": "inaccurate recommendation outcomes. That is due to the fact that attackers tend to add items that are",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 23,
    "content": "irrelevant to users’ behaviors for hindering collaborative knowledge learning [ 14, 7 ]. In order to defend such minor perturbations for robust recommendations, one of the promising solutions is to purify",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 24,
    "content": "malicious collaborative knowledge from the user’s historical interactions towards items in LLM-based\nrecommender systems. In most recommender systems, collaborative graphs based on item-item\nco-occurrence are commonly employed as a collaborative signal to represent the relationships among",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 25,
    "content": "items, where items frequently interacted together by different users are related (e.g., substitutable or\ncomplementary) [ 42, 33 ]. Following the insertion of perturbations by attackers, item co-occurrence",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 26,
    "content": "collaborative graphs as the external knowledge source can provide valuable evidence on whether\nsuch perturbations are relevant to other items in the user’s interaction history and effectively filter out",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 27,
    "content": "malicious collaborative signals (i.e., perturbed items), which can be achieved by retrieving subgraphs\nand examining the connection between the perturbation and the retrieved subgraphs.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 28,
    "content": "Recently, to mitigate the problems usually caused by insufficient intrinsic knowledge of LLMs, including outdated knowledge, hallucination, and so on [ 52, 16, 29, 41 ], retrieval-augmented generation\n(RAG) techniques [ 15 ] have been proposed to expand the internal knowledge of large language",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 29,
    "content": "models with an external database. The relevant knowledge is retrieved from the external database",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 30,
    "content": "2\n\n\n-----",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 31,
    "content": "and employed to augment LLMs without changing the parameters of LLM backbone, achieving\noutstanding success for various knowledge-intensive domains such as open question answering [ 28 ],\nmedicine [ 17 ], and finance [ 32, 71 ]. For example, Lewis et al. [28] propose to utilize Wikipedia for",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 32,
    "content": "knowledge retrieval and combine the retrieved documents with the input to augment the generation\nprocess, significantly improving the performance of LLMs for various complex tasks and mitigating\nthe hallucination problem. In the context of RecSys, there exists a vast amount of publicly available",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 33,
    "content": "external collaborative knowledge collected from various public platforms such as Amazon [ 37 ],\nYelp [ 40 ], and Steam [ 46 ]. Given the success of expanding the internal knowledge of LLMs through\nthe use of external databases to enhance their capabilities in a training-free manner, along with the",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 34,
    "content": "abundant collaborative knowledge available in the RecSys community, RAG techniques provide\nunprecedented opportunities to enhance the robustness of LLM-empowered RecSys with external\ncollaborative signals. For example, as shown in Figure 1, LLM-empowered RecSys might generate",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 35,
    "content": "an incorrect recommendation to a user who interacted with \"skirt, ties, heels\". To produce reliable\nrecommendation results, a collaborative item graph (i.e., external databases) based on user-item",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 36,
    "content": "interactions can be constructed to provide useful external collaborative knowledge for better understanding users’ preferences in LLM-based recommender systems. LLM-based RecSys can purify\nthe noisy users’ online behaviors (i.e., perturbation \"ties\") by retrieving collaborative signals (i.e.,",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 37,
    "content": "subgraph) from the collaborative item graph for recommendation generation, where items \"skirt\" and\n\"heels\" rarely appear together with \"ties\" in most users’ shopping behaviors.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 38,
    "content": "To effectively take advantage of external collaborative signals from item-item collaborative graph, in\nthis paper, a novel framework **RETURN** is proposed as a ret rieval-a u gmented p u r ifier for e n hancing",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 39,
    "content": "the robustness of LLM-empowered recommender systems in a plug-and-play manner. Specifically,\nthe users’ historical sequences within the external databases are first encoded into collaborative\nitem graphs to capture the extensive collaborative knowledge. After that, a retrieved-augmented",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 40,
    "content": "perturbation positioning strategy is proposed to identify potential perturbations by retrieving relevant\ncollaborative signals from the collaborative item graphs. Then, we further cleanse the potential\nperturbations within the user profile by using either deletion or replacement strategies based on",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 41,
    "content": "the external collaborative item graphs. Finally, a robust ensemble recommendation strategy is\nproposed to guide the LLM-empowered RecSys to generate robust recommendation results. Our\nmajor contributions are summarised as follows:",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 42,
    "content": "- We introduce a novel strategy for denoising in LLM-empowered recommendation, in which\ntraining-free retrieval-augmented denoising strategy is proposed to leverage the collaborative\nsignals of collaborative item graphs to purify the poisoned user profiles.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 43,
    "content": "- We propose a novel framework ( **RETURN** ) to enhance the robustness of LLM-empowered\nRecSys by harnessing collaborative signals from external databases in a plug-and-play\nmanner. Meanwhile, a robust ensemble recommendation is proposed to cleanse user profiles",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 44,
    "content": "multiple times and generate robust recommendations by using a decision fusion strategy.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 45,
    "content": "- We conduct extensive experiments on three real-world datasets to demonstrate the effectiveness of the proposed method. Comprehensive results indicate that RETURN can significantly",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 46,
    "content": "mitigate the negative impact of the perturbations, highlighting the potential of introducing external collaborative knowledge to enhance the robustness of LLM-empowered recommender\nsystems.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 47,
    "content": "The rest of this paper is organized as follows: Section 2 reviews multiple related studies. Section 3\nprovides the basic definition of the research problem, and the details of the proposed RETURN are",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 48,
    "content": "presented in Section 4. Then, we conduct comprehensive experiments to investigate the effectiveness\nof RETURN in Section 5. Finally, we conclude the whole work in Section 6.\n### **2 Related Works**",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 49,
    "content": "**2.1** **Defense Strategies for LLMs**\n\nNumerous defense strategies have been devised to mitigate LLM vulnerabilities and safeguard against\nharmful information in LLM responses. These methods are categorized into two main classes based\non whether they are employed during training or inference.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 50,
    "content": "***1) Defense in LLMs Training.*** The security of LLMs is significantly dependent on their training\ndata, resulting in several defense strategies aimed at enhancing and purifying the training data [ 47 ].\n\n3\n\n\n-----",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 51,
    "content": "For example, Wenzek et al. [66] introduced CCNet, an automated pipeline designed to efficiently\nextract vast amounts of high-quality monolingual datasets from the Common Crawl corpus across\nvarious languages. Beyond enhancing the quality of training data, adversarial training techniques [ 3 ]",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 52,
    "content": "are widely employed to guide LLMs towards appropriate behaviors by introducing adversarial\nperturbations into training examples to improve model robustness and performance [ 70 ]. For example,\nLiu et al. [39] introduced a general algorithm known as adversarial training for large neural language",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 53,
    "content": "models (ALUM), aimed at enhancing the robustness of language models. ALUM enhances model\nresilience by regularizing the training objective via incorporating perturbations within the embedding\nspace and focusing on maximizing adversarial loss. Wang et al. [59] ) propose a simple yet effective",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 54,
    "content": "adversarial training method that incorporates adversarial perturbations into the output embedding layer\nduring model training. Li and Qiu [30] employs a token-level accumulated perturbation vocabulary",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 55,
    "content": "to initialize the adversarial perturbations and use a token-level normalization ball to regulate the\ngenerated perturbations for virtual adversarial training [8].",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 56,
    "content": "***2) Defense in LLMs Inference.*** The large scale of parameters of LLMs renders their retraining or\nfine-tuning processes both time-consuming and computationally expensive. Therefore, training-free",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 57,
    "content": "defense methods during inference have drawn considerable attention [ 70 ]. For example, Kirchenbauer\net al. [26] and Jain et al. [23] undertake extensive experiments to evaluate the effectiveness of\ndifferent defense methods, such as perplexity-based detection, retokenization, and paraphrasing. Li",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 58,
    "content": "et al. [31] introduce an adversarial purification method that masks input texts and leverages masked\nlanguage models [ 25 ] for text reconstruction. Wei et al. [65] and Mo et al. [43] propose enhancing\nmodel robustness through contextual demonstrations. Wang et al. [63] propose RMLM, aimed",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 59,
    "content": "at countering attacks by confusing attackers and correcting adversarial contexts stemming from\nmalicious perturbations. Helbling et al. [22] incorporate generated content into a predefined prompt\nand utilize another LLM to analyze the text and assess its potential harm.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 60,
    "content": "**2.2** **LLM-Empowered Recommender Systems**",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 61,
    "content": "Currently, LLMs are widely employed in enhancing the capabilities of recommender systems due to\ntheir powerful language understanding, logical reasoning, and generation abilities. These studies can\nbe generally divided into three categories based on the item information utilized.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 62,
    "content": "***1) ID-Based LLM-Empowered Recommender Systems.*** ID-based LLM-empowered recommender\nsystems represent an item with a numerical index and use the item IDs for recommendations [ 18, 78 ].\nFor example, Geng et al. [18] propose P5, which unifies various recommendation tasks by converting",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 63,
    "content": "user-item interactions to natural language sequences. P5 introduces whole-word embedding to\nrepresent the token IDs, bridging the gap between large language models and recommender systems.\nZheng et al. [78] propose a learning-based vector quantization method for assigning meaningful",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 64,
    "content": "item indices for items and introduce specialized tasks to facilitate the integration of collaborative\nsemantics in LLMs, leading to an effective adaptation to recommender systems.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 65,
    "content": "***2) Text-Based LLM-Empowered Recommender Systems.*** To effectively harness the natural language\nunderstanding and generation capabilities of LLMs, text-based LLM-empowered recommender",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 66,
    "content": "systems primarily leverage textual information such as item titles and item descriptions for recommendation [ 11, 4 ]. For example, Bao et al. [4] introduce TALLRec, a novel tuning paradigm designed\nto tailor LLMs for recommendation tasks effectively, guides the model to assess user interest in a",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 67,
    "content": "target item by analyzing their historical interactions that encompass textual descriptions like item\ntitles. Du et al. [11] propose a novel LLM-based approach for job recommendation that enhances\nuser profiling for resume completion by extracting both explicit and implicit user characteristics",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 68,
    "content": "based on users’ self-description and behaviors. A GANs-based method is introduced to refine the\nrepresentations of low-quality resumes, and a multi-objective learning framework is utilized for job\nrecommendations.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 69,
    "content": "***3) Hybrid LLM-Empowered Recommender Systems.*** These approaches effectively integrate both\ntextual information and ID-based knowledge to generate recommendations [ 34, 53 ]. For example,\nRen et al. [53] leverage text-format knowledge from LLMs and item IDs to enhance recommendation",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 70,
    "content": "performance, along with a novel alignment training method and an asynchronous technique to refine\nLLMs’ generation process for improved knowledge augmentation and accelerated training. Liao\net al. [34] propose a novel hybrid prompting approach that integrates ID-based item embedding",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 71,
    "content": "generated by traditional RecSys with textual item features. Besides, LLaRA utilizes a projector to\nalign traditional recommender ID embeddings with LLM input space and incorporates a curriculum",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 72,
    "content": "4\n\n\n-----\n\nlearning strategy to gradually train the model to integrate behavioral knowledge from traditional\nsequential recommenders, thereby enhancing recommendation performance seamlessly.\n\n**2.3** **Denoising for Traditional Recommender Systems**",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 73,
    "content": "With the development of RecSys, a growing body of research has focused on their vulnerability\nto noisy data, subsequently driving the advancement of various denoising approaches to improve\nsystem robustness [ 60, 36, 75, 55 ]. For example, GraphRfi [ 75 ] proposes an innovative end-to-end",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 74,
    "content": "framework that integrates Graph Convolutional Networks (GCN) and neural random forests to\nsimultaneously enhance robust recommendation accuracy and fraudster detection. By leveraging\nuser reliability features and prediction errors of RecSys, GraphRfi effectively mitigates the impact of",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 75,
    "content": "shilling attacks [ 54, 19 ]. LoRec [ 73 ] proposes to enhance the robustness of sequential recommender\nsystems against poisoning attacks by integrating the open-world knowledge of large language models.\nThrough LLM-Enhanced Calibration, LoRec employs a user-wise reweighting strategy to generalize",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 76,
    "content": "defense mechanisms beyond specific known attacks, effectively mitigating the impact of fraudsters.\nLLM4DASR [ 58 ] introduces an LLM-assisted denoising framework for sequential recommendations,\ncombining self-supervised fine-tuning with uncertainty estimation to address output quality challenges.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 77,
    "content": "This model-agnostic framework effectively identifies and corrects noisy interactions, enhancing\nrecommendation performance across various models.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 78,
    "content": "**2.4** **Difference between Existing Denoising Approaches and RETURN**\n\nDespite the presence of existing denoising techniques, they are fundamentally different from our\napproach in terms of task formulation and technical details:",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 79,
    "content": "1) **Denoising for different phases.** Existing denoising methods primarily focus on purifying\nthe training set and ensuring accurate representation learning for RecSys to mitigate the impact of\nshilling attacks during training, assuming that user historical interactions during inference contain",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 80,
    "content": "no perturbations. However, during the inference phase, users may still be attracted to clickbait\nitems and interact with them, leading to perturbations that do not align with their true preferences.\nMoreover, studies [ 45 ] have highlighted the vulnerability of LLM-empowered recommender systems",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 81,
    "content": "during inference, where even a **well-trained** LLM-based RecSys frequently produces inaccurate\nrecommendations for users affected by poisoned interactions. In other words, even after the training\nset has been purified, if a user inadvertently interacts with a few clickbait or disliked items during",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 82,
    "content": "inference, LLM-empowered RecSys may still misinterpret the user’s preferences and generate\nunsatisfied recommendations. In this paper, we assume that the LLM-empowered RecSys is welltrained, while user interaction sequences may contain noise or adversarial perturbations during",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 83,
    "content": "inference. In other words, RETURN is designed to address the **inference-phase vulnerability of**\n**LLM-empowered RecSys** and enhance their robustness, which is fundamentally different from the\nobjective of previous denoising methods. Additionally, RETURN can be seamlessly integrated with",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 84,
    "content": "prior denoising approaches. For instance, existing methods can be employed to cleanse the training\nset and train a powerful LLM-empowered RecSys, while RETURN ensures the robustness of the\nRecSys during the inference phase.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 85,
    "content": "2) **Novel purification techniques based on external collaborative signals.** Existing denoising\nmethods primarily rely on leveraging the characteristics of perturbations [ 60, 75, 55 ] or the open-world",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 86,
    "content": "knowledge of LLMs [ 73, 58 ] to identify perturbations within the training set, largely overlooking\nthe potential of external collaborative knowledge. With the advancement of recommender systems,\nnumerous publicly available datasets have been introduced to evaluate algorithm performance. These",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 87,
    "content": "datasets offer abundant external collaborative signals that can be leveraged to purify perturbations\nwithin user historical interactions. Specifically, after attackers introduce perturbations, collaborative",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 88,
    "content": "graphs based on item-item co-occurrence can be constructed from the external database and leveraged\nto assess whether these perturbations are consistent with other items in the user’s interaction history,",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 89,
    "content": "thereby effectively filtering out malicious collaborative signals (i.e., perturbed items). Therefore,\nRETURN effectively extracts collaborative knowledge from external databases to purify the user\nhistorical interactions in a plug-and-play manner, providing a promising solution for enhancing the",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 90,
    "content": "robustness of LLM-empowered RecSys.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 91,
    "content": "5\n\n\n-----\n\n### **3 Problem Statement**\n\n**3.1** **Notation and Definition**",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 92,
    "content": "The objective of recommender systems is to capture the users’ preferences from their historical interactions, such as browsing, clicking, and purchasing. In the era of LLMs, the recommendation task",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 93,
    "content": "is usually converted to the natural language format, consisting of user *u* *i* *∈* *U* = *{u* 1 *, u* 2 *, ..., u* *|U* *|* *}*,",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 94,
    "content": "and user’s interaction history (also called user’s profile) *I* *u* *i* = [ *I* 1 *, I* 2 *, ..., I* *|I* *ui* *|* ], and a recommendation prompt *P* = [ *p* 1 *, p* 2 *, ..., p* *|P|* ], where *p* *i* is the textual token used to guide the RecSys *R* *θ* to",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 95,
    "content": "generate recommendations. *I* *i* *∈I* = *{I* 1 *, I* 2 *, ..., I* *|I|* *}* is the interacted item from the item pool *I*\nof user *u* *i* . Based on the above definition, a textual recommendation query can be represented as",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 96,
    "content": "**x** = [ *P ◦* *u* *i* *◦I* *u* *i* ], where *◦* represents inserting the information of user *u* *i* and the corresponding\ninteraction list *I* *u* *i* into the designated position of prompt *P* . For example, as shown in Figure 2, after",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 97,
    "content": "inserting the user information and item interaction sequence into the prompt *P*, the specific input\nused for recommendation can be denoted by:",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 98,
    "content": "*P* =[what, is, the, top, recommended, item, for, [ *User* _ 2 35 ] *,*\n(1)\nwho, interacted, with, [ *item* _ 123 *,* *...* *,* *item* _ 928] *,* ?] *,*",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 99,
    "content": "where *u* *i* = [ *User* _235] and *I* *u* *i* = [ *item* _123 *, ..., item* _928] are the specific user and the historical\ninteractions of user *u* *i*, respectively. In different LLM-empowered RecSys, *I* *u* *i* can take various",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 100,
    "content": "forms, such as numeric IDs [ 18 ] or item titles [ 4 ] for recommendations. Assume the target item is **y**,\nthe performance of the LLM-empowered RecSys can be defined by:",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 101,
    "content": "*D* ( *R* *θ* ( **x** ) *,* **y** ) *,* (2)",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 102,
    "content": "where *D* evaluates the discrepancy between the generated recommendations *R* *θ* ( **x** ) and the ground\ntruth. During training, the negative log-likelihood function could be used as the *D*, while during",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 103,
    "content": "inference, the Hit Ratio or Normalized Discounted Cumulative Gain (NDCG) [ 18 ] could be employed\nto evaluate the recommendation performance.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 104,
    "content": "**3.2** **Vulnerabilities of LLM-Based RecSys**",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 105,
    "content": "The vulnerabilities of LLM-based RecSys refer to the phenomenon where the model’s recommendation outcomes vary significantly due to minor perturbations in the input [ 45 ]. Such vulnerabilities\nsignificantly deteriorate the overall user experience and compromise the effectiveness of RecSys.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 106,
    "content": "For example, assuming a user *u* *i* inadvertently clicks on some items they are not actually interested in, leading to a change in their interaction history from *I* *u* *i* to *I* [ˆ] *u* *i* = I( *I* *u* *i* *◦* *δ|s* ), where",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 107,
    "content": "I( *I* *u* *i* *◦* *δ|s* ) represent to insert perturbation *δ* into user’s profile *I* *u* *i* at position *s* . The vulnerability\nof LLM-empowered RecSys may lead the system to recommend items that the user is not interested",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 108,
    "content": "in, consequently resulting in a decline in user experience. As an attacker, the perturbations *δ* can be\ngenerated intentionally by optimizing the following equation:",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 109,
    "content": "*δ* = arg max *D* ( *R* *θ* (ˆ **x** ) *,* **y** ) *,* (3)\n*δ* : *|δ|≤△*",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 110,
    "content": "where ˆ **x** = [ *P ◦* *u* *i* *◦* *I* [ˆ] *u* *i* ] is the perturbed input and *△* constrains the magnitude the perturbations. *D*\nevaluates the discrepancy between the generated recommendations *R* *θ* ( **x** ) and the ground truth.\n\n**3.3** **Robust LLM-based Recommendation**",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 111,
    "content": "The primary objective of robust LLM-based recommendations is to prevent the negative impact\nof the perturbations contained in the users’ profiles, thereby enhancing the system’s reliability\nand robustness. There are mainly two approaches to achieve this goal: adversarial training-based",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 112,
    "content": "methods [ 67 ] and training-free methods [ 56 ]. Adversarial training-based methods intentionally\ncreate multiple perturbed training samples to guide the RecSys in learning patterns of perturbations,\nthereby improving system robustness. However, these methods usually retrain or fine-tune the whole",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 113,
    "content": "RecSys, which is extremely time-consuming due to the large number of trainable parameters in\nLLMs. Consequently, this paper primarily concentrates on the training-free methods, which improve",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 114,
    "content": "6\n\n\n-----\n\n|Whatis the top recommended item for user_235 who interacted with|item_1009,|item_g|2oo2d9s8,it|em_1109,|\n|---|---|---|---|---|",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 115,
    "content": "Figure 2: The overall framework of the proposed RETURN. The user interaction sequences in\nthe external database are first converted to multi-hop collaborative item graphs. The occurrence\nprobability of each item is computed based on the collaborative item graph for perturbation positioning.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 116,
    "content": "Finally, we purify the input prompt by retrieving collaborative signals from the collaborative item\ngraphs for robust recommendation generation.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 117,
    "content": "the model’s robustness without introducing additional changes in model parameters. Specifically,\nwhen the users’ profiles contain adversarial perturbations, we aim to accurately identify and filter out",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 118,
    "content": "these perturbations to ensure the appropriate recommendations for users during the inference process.\nMathematically, if the input with adversarial perturbations is denoted by ˆ **x**, we aim to cleanse the\ninput for robust recommendations, formulated as follows:",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 119,
    "content": "¯ **x** = arg min *D* ( *R* *θ* (C(ˆ **x** )) *,* **y** ) *,* (4)\n\nwhere C(ˆ **x** ) represents purifying input ˆ **x** containing perturbations into a benign prompt ¯ **x** .\n\n### **4 Methodology**\n\n**4.1** **An Overview of the RETURN**",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 120,
    "content": "RETURN is proposed to leverage the collaborative knowledge of users within external databases\nto filter out adversarial perturbations, thereby enhancing the robustness of the existing LLM-based\nRecSys. As shown in Figure 2, RETURN mainly contains three components: Retrieval-Augmented",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 121,
    "content": "Perturbation Positioning, Retrieval-Augmented Denoising, and Robust Ensemble Recommendation.\nFirst, we convert the user interaction sequences within the external database to collaborative item\ngraphs to encode the collaborative knowledge without introducing additional training processes. After",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 122,
    "content": "that, the probability of each item in the user profile being a perturbation is computed by retrieving\ncollaborative signals from collaborative item graphs. Second, retrieval-augmented denoising filters",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 123,
    "content": "out the potential perturbations in the user profiles using either deletion or replacement strategies\nbased on the collaborative signals of the generated item graphs. Finally, robust ensemble recommendation purifies input query multiple times and adopts an ensemble strategy to generate the final",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 124,
    "content": "recommendations.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 125,
    "content": "**4.2** **Retrieval-Augmented Perturbation Positioning**",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 126,
    "content": "To mitigate the negative impact of perturbations, the first crucial step is to accurately locate the\nperturbations from extensive interactions within user profiles. To achieve this goal, we propose to",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 127,
    "content": "use collaborative item graphs to encode the collaborative signals from users in the external database\nand retrieve relevant collaborative knowledge for perturbation positioning. By encoding the user’s",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 128,
    "content": "interaction history into collaborative item graphs, we can clearly understand the relationships between\nitems [ 74 ], and such strong collaborative signals can provide evidence for subsequent denoising",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 129,
    "content": "7\n\n\n-----\n\nprocesses. Furthermore, this approach enables the direct use of a one-hot vector for information\nretrieval, eliminating the need to explicitly train a universal retriever as required by other RAG\ntechniques, thereby improving efficiency.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 130,
    "content": "**4.2.1** **Collaborative Item Graph Generation**",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 131,
    "content": "Let *E* = *{U* *E* *, I* *E* *}* be the external database, where *U* *E* = *{u* 1 *, u* 2 *, ..., u* *E* *}* and *I* *E* =",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 132,
    "content": "*{I* *u* 1 *, I* *u* 2 *, ..., I* *u* *E* *}* denote the users and their interaction sequences, respectively. The most straightforward method of generating collaborative item graphs is to count the occurrence frequency of *i* -th",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 133,
    "content": "and *j* -th items appearing together in the historical interaction of the same user. However, such a\nvanilla strategy overlooks the temporal relationships among items, which are significantly crucial for",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 134,
    "content": "subsequent denoising processes. For instance, mobile phones and phone cases are usually interacted",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 135,
    "content": "with consecutively by users, whereas mobile phones and furniture are typically not sequentially interacted with by users. During the denoising process, if a user consecutively interacts with both mobile",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 136,
    "content": "phones and furniture, there is a high likelihood of perturbations in the user’s historical interactions.\nTherefore, to provide precise collaborative signals, we also consider the gap between two items and",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 137,
    "content": "generate a set of multi-hop collaborative item graphs, which encode not only the relevance between\nitems but also the temporal relationships of items. Given the external database *E* = *{U* *E* *, I* *E* *}*, the\nmulti-hop collaborative item graph can be represented as:",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 138,
    "content": "*G* *ϵ* = *{I, C* *I* *[ϵ]* *i* *,I* *j* *[}]* [ =] *[ {I][,]* [ T][(] *[C]* *I* *[ϵ]* *i* *,I* *j* *[|][u]* *[z]* *[, ϵ]* [)] *[}][,]* (5)",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 139,
    "content": "where the *ϵ* -hop collaborative item graph contains nodes *I* and edges *C* *I* *[ϵ]* *i* *,I* *j* [, respectively. The edge]\n*C* *I* *[ϵ]* *i* *,I* *j* [stores the co-occurrence frequency of two items.] [ T][(] *[·]* [)] [ is a counting function. If two items]",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 140,
    "content": "*I* *i* and *I* *j* appear simultaneously within the historical interactions of user *u* *z* with a gap of *ϵ* items\nbetween them, the co-occurrence frequency *C* *I* *[ϵ]* *i* *,I* *j* [is increased by one, defined by:]",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 141,
    "content": "T( *C* *I* *[ϵ]* *i* *,I* *j* *[|][u]* *[z]* *[, ϵ]* [)] *[}]* [ =] � *CC* *II* *[ϵ][ϵ]* *ii* *,I,I* *jj* *[,]* [+ 1] *[,]* ifotherwise *I* *i* *, I* *j* *∈I .* *u* *z* *, |i −* *j|* = *ϵ,* (6)\n\n**4.2.2** **Perturbation Positioning**",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 142,
    "content": "After encoding the external users’ collaborative knowledge into collaborative item graphs, the next\nstep is to locate the perturbations within the input query based on the generated graphs. Specifically,",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 143,
    "content": "if one item has never appeared together with the remaining items in the user’s historical interactions\nbased on the collaborative item graphs derived from the majority of users’ behavior, this indicates",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 144,
    "content": "that such item is unrelated to the other items the user has interacted with. Thus, the likelihood of this",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 145,
    "content": "item appearing within the user’s interaction history is minimal, and the occurrence of such a lowprobability event strongly implies that this item is likely introduced as a perturbation by an attacker.\nTherefore, to accurately locate the potential perturbations, we propose to retrieve co-occurrence",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 146,
    "content": "frequency from the collaborative item graphs and assess the probability of each item appearing within\nthe user’s interaction history.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 147,
    "content": "Given the multi-hop collaborative item graphs *G* *ϵ* and the user’s historical interactions *I* *u* *i* =\n\n[ *I* 1 *, I* 2 *, ..., I* *|I* *ui* *|* ], the co-occurrence frequency for a pair of items can be defined as:",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 148,
    "content": "R ( *I* *i* *,* *I* *j* *|* *G* *ϵ* )\n*o* *i,j* = � *z∈* [1 *,|I|* ] [R][(] *[I]* *[i]* *[, I]* *[z]* *[|G]* *[ϵ]* [)] *[,]* (7)",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 149,
    "content": "where *ϵ* = *|j −* *i|* is the gap between *i* -th and *j* -th items and R( *I* *i* *, I* *j* *|G* *ϵ* ) represent to retrieve the\nco-occurrence frequency between *i* -th and *j* -th items from the *ϵ* -hop collaborative item graph. By",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 150,
    "content": "traversing each pair of items in the user’s historical interactions, the occurrence probability of each\nitem is denoted by:\n*A* = [ *A* 1 *, ..., A* *|I* *ui* *|* ] *,*",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 151,
    "content": "(8)\n*A* *i* = [�] *j* *[|I]* =1 *[uz]* *,j* *[ |]* = *̸* *i* *[o]* *[i,j]* *[.]*\n\nA smaller value of *A* *i* indicates a lower probability of the current item co-occurring with other items,\nmaking it more likely to be a perturbation.\n\n8\n\n\n-----\n\n**4.3** **Retrieval-Augmented Denoising**",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 152,
    "content": "Once the occurrence probability of each item has been computed, it is necessary to purify the input\nquery based on such collaborative knowledge. However, directly removing numerous items that\nmay be perturbations usually leads to the RecSys failing to capture the user’s preferences accurately",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 153,
    "content": "since there are limited remaining interactions. To mitigate the negative impact of perturbations\nwhile maintaining the integrity of user interaction sequences, a hybrid strategy is proposed to\neliminate a small subset of items that are most likely perturbations and replace the remaining potential",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 154,
    "content": "perturbations with items that align with the user’s preferences.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 155,
    "content": "If an item’s occurrence probability *A* *i* = 0, it indicates that this item has never co-occurred with\nthe other items in the user’s historical interactions based on the collaborative signals of most users",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 156,
    "content": "from external databases. Thus, this item is highly likely a perturbation inserted by attackers due to\nits lack of relevance to the user’s other interaction items, and its deletion typically helps RecSys",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 157,
    "content": "accurately capture the user’s genuine preferences. Mathematically, given the interaction history *I* *u* *i*\nof the user *u* *i* and the occurrence probability *A*, we first delete the most likely perturbation items\nwhose occurrence probability is zero, defined by:",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 158,
    "content": "C *d* ( *I* *i* *→∅|A* *i* ) = 1( *I* *i* *, A* *i* ) *,* (9)\n\nwhere 1( *I* *i* *, A* *i* ) represents to execute deletion operation when *A* *i* = 0 and preservation otherwise.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 159,
    "content": "After removing items with *A* *i* = 0 that are most likely perturbations, some items usually remain in\nthe user’s historical interactions with very low but non-zero occurrence probabilities. Simply deleting",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 160,
    "content": "these items usually results in sparse user-item interactions, and such limited collaborative knowledge",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 161,
    "content": "leads to cold start issues [ 64 ], hindering RecSys from capturing user preferences effectively. To maintain the integrity of user interaction history, a retrieval-augmented replacement strategy is proposed to",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 162,
    "content": "replace the remaining potential perturbations with items that align with user preferences. Specifically,\nall items that have co-occurred with the other remaining items in the user’s interaction history are",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 163,
    "content": "retrieved from the collaborative item graphs, and the item that shows the highest co-occurrence\nfrequency is considered the prime candidates that best align with the current user preferences among",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 164,
    "content": "all the retrieved items. Given the user’s historical interactions *I* *u* *i* = [ *I* 1 *, ..., I* *I* *|ui|* ] and the potential\nperturbation *I* *i* with the low occurrence probability, the replacement operation is defined by:",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 165,
    "content": "*|I* *ui* *|* R ( *I* *j* *|* *G* *ϵ* ) *· A* *j*\n\nC *r* ( *I* *i* *→* *I* [¯] *i* *|A* *i* ) = arg max ¯ � (10)\n*I* *i* *j* =1 *,j* = *̸* *i* � *z∈* [1 *,|I|* ] [R][(] *[I]* *[j]* *[, I]* *[z]* *[|G]* *[ϵ]* [)] *[,]*",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 166,
    "content": "where *I* ¯ *i* that better align with user preferences. C *r* ( *I* *i* *→* *I* [¯] *i* *|A* *i* ) represents to replace the potentially perturbed item R( *I* *j* *|G* *ϵ* ) represent to retrieve the co-occurrence frequency *I* *i* with alternative items",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 167,
    "content": "between item *I* *j* and all items that have co-occurred with *I* *j* from the item pool *I* based on the *ϵ* -hop\ncollaborative item graph *G* *ϵ*, where *ϵ* = *|j −* *i|* . *A* *j* is considered as a weight, where a larger *A* *j*",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 168,
    "content": "indicates a closer alignment between the current item *I* *j* and the user’s preference, thus resulting in\ngreater weights assigned to items that are likely to co-occur with it.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 169,
    "content": "**4.4** **Robust Ensemble Recommendation**",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 170,
    "content": "Due to the uncertainty regarding the number of perturbations, determining the extent of purification\napplied to the user’s historical interactions is a challenging task. Excessive modification of items leads",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 171,
    "content": "to difficulties in capturing the user’s intrinsic preferences, thereby diminishing the recommendation\nperformance. Conversely, the limited purification of items results in perturbations still existing in",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 172,
    "content": "user profiles, making it challenging to enhance the robustness of RecSys. To tackle this challenge, we\npropose a robust ensemble recommendation approach. Specifically, we first randomly purify varying",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 173,
    "content": "numbers of items in the user’s profile and generate a set of cleansed inputs. These cleansed prompts\nare fed into the LLM-based RecSys, and the final recommendations are obtained by adopting a voting",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 174,
    "content": "mechanism [ 27 ]. Technically, we randomly sample an integer *n* from a normal distribution. Top- *n*\nitems *I* [ˆ] *u* *[n]* *i* [= [] *[I]* [1] *[, I]* [2] *[, ..., I]* *[n]* []] [ with the lowest occurrence probabilities are identified from the user’s]",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 175,
    "content": "historical interactions based on *A* and deletion C *d* or substitution C *r* operations are performed on\nthese items. The purified user profile is defined by:",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 176,
    "content": "*I* ¯ *u* *i* = [C( *I* 1 *|A* 1 *, n* ) *, ...,* C( *I* *u* *i* *|A* *u* *i* *, n* )] *,* (11)\n\n9\n\n\n-----\n\n**Al** **g** **orithm 1: RETURN**",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 177,
    "content": "9\n\n\n-----\n\n**Al** **g** **orithm 1: RETURN**\n\n**Input:**\nInput ˆ **x**, External database *E*, Purification cycle *m*, LLM-empowered RecSys *R* *θ* .\n**Output:** Robust recommendations ¯ **y** .\n**Procedure:**\n\n**1** Generate multi-hop collaborative item graph *G* *ϵ* according to Eq (5) ;",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 178,
    "content": "**2** Retrieve the co-occurrence frequency for a pair of items within *I* *u* *i* according to Eq (7) ;\n\n**3** Compute the occurrence probability for each item within *I* *u* *i* according to Eq (8) ;\n\n**4** **for** *t in 1:m* **do**",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 179,
    "content": "**4** **for** *t in 1:m* **do**\n\n**5** Purify the user’s historical interactions according to Eq (12) ;\n\n**6** Generate the recommendations for each purified prompt ¯ **x** *i* and obtain a set of\nrecommendation results [ *R* *θ* (¯ **x** 1 ) *, R* *θ* (¯ **x** 2 ) *, ..., R* *θ* (¯ **x** *m* )] ;",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 180,
    "content": "**7** Generate the final recommendations based on Eq (13) ;\n\nwhere C( *I* *i* *|A* *i* *, n* ) is the purifying process:\n\n C *d* ( *I* *i* *→∅|A* *i* ) *,* if *I* *i* *∈* *I* [ˆ] *u* *[n]* *i* [and] *[ A]* *i* [= 0] *[,]*",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 181,
    "content": "C( *I* *i* *|A* *i* *, n* ) = C *r* ( *I* *i* *→* *I* [¯] *i* *|A* *i* ) *,* if *I* *i* *∈* *I* [ˆ] *u* *[n]* *i* [and] *[ A]* *i* *[̸]* [= 0] *[,]* (12)\n\n\n\n *I* *i* *,* if *I* *i* */∈* *I* [ˆ] *u* *[n]* *i* *[.]*",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 182,
    "content": "By repeating the purification process multiple times on *I* *u* *i*, we can obtain *m* cleansed user profiles,\nwhere *m* is a hyperparameter. These purified prompts are individually fed into the LLM-empowered",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 183,
    "content": "RecSys, and the results are subsequently integrated to produce the final recommendation output by\nusing voting mechanisms, defined by:",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 184,
    "content": "¯ **y** = *V oting* ( *R* *θ* (¯ **x** 1 ) *, R* *θ* (¯ **x** 2 ) *, ..., R* *θ* (¯ **x** *m* )) *,* (13)",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 185,
    "content": "where ¯ **x** *i* = [ *P ◦* *u* *i* *◦* *I* [¯] *u* *i* ] is the purified input and ¯ **y** is the final recommendation. The pseudo-code\nof RETURN is shown in **Algorithm** 1.\n### **5 Experiments**\n\n**5.1** **Experimental Details**\n\n**5.1.1** **Datasets.**",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 186,
    "content": "All experiments are conducted on three real-world datasets in RecSys: Movielens-1M ( **ML1M** ) [ 20 ],\n**Taobao** [ 79 ], and **LastFM** [ 68 ] datasets. The ML1M dataset contains one million movie ratings",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 187,
    "content": "collected from around 6,040 users and their interactions with around 4,000 movies, which is widely\nused for various recommendation tasks and evaluation of recommendation techniques. The LastFM",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 188,
    "content": "dataset is a widely used music recommendation dataset that contains user listening histories and preferences, which is frequently used to study user preferences, understand music consumption patterns,\nand evaluate recommendation algorithms. The Taobao dataset comprises a massive collection of user",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 189,
    "content": "interactions on the Taobao e-commerce platform, including browsing, searching, and purchasing\nactivities. It consists of a million records from around 987,994 users and their interactions with\naround 4,162,024 items and offers valuable insights into user behavior and preferences in the online",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 190,
    "content": "retail environment. For **P5** model, all the aforementioned datasets are preprocessed following the\nstrategies proposed by Xu et al. [68] . For **TALLRec** model, it needs to divide the users’ historical",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 191,
    "content": "sequences into users’ liked items and disliked items based on their ratings. Since LastFM and Taobao\ndatasets lack rating information from users, we only process the **ML1M** dataset according to the\nstudy of Ning et al. [45].",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 192,
    "content": "**5.1.2** **Victim LLM-based Recommender Systems.**\n\nTwo representative LLM-based RecSys, i.e., **P5** and **TALLRec**, are employed as the victim models\nto investigate the performance of different defense techniques.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 193,
    "content": "- **P5** is a typical ID-based LLM-empowered RecSys, which assigns each item a numerical number\nand converts the user-item interactions to natural language sequences for recommendations. P5\n\n10\n\n\n-----",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 194,
    "content": "10\n\n\n-----\n\nintroduces several item indexing strategies, which can be employed to test the robustness of the\ndefense methods for ID-based RecSys with different indexing strategies.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 195,
    "content": "- **TALLRec** is a representative text-based LLM-empowered recommender system, which integrates\ntextual information (i.e., item title) into a pre-defined prompt template for recommendation. By\nconstructing experiments based on TALLRec, we can investigate the performance of different",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 196,
    "content": "defense methods for LLM-empowered RecSys employing textual knowledge.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 197,
    "content": "**5.1.3** **Attackers.**",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 198,
    "content": "We employ CheatAgent [ 45 ] as the attacker to generate adversarial perturbations and insert them into\nthe user’s historical interactions. It should be noted that CheatAgent is an evasion attack method",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 199,
    "content": "that uses LLMs as the agent to generate high-quality perturbations for misleading the target LLMempowered RecSys during the inference phase. Currently, there is limited research on poisoning\nattacks for LLM-empowered RecSys. Poisoning attacks require retraining the model, but the large",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 200,
    "content": "parameter size of LLMs makes frequent retraining infeasible. In other words, poisoning attacks are\nhighly time-consuming for large language models, and they are ineffective if retraining cannot be\nperformed. Therefore, in this paper, we solely consider the evasion attack (i.e., CheatAgent) since",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 201,
    "content": "it is a more efficient attacking method in the era of LLMs. We use CheatAgent to generate item\nperturbations and insert them into the user’s history interactions to test the defense performance\nof different methods. The primary objective of CheatAgent is to investigate the vulnerabilities of",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 202,
    "content": "exiting LLM-empowered RecSys, and it allows the insertion of perturbations in both prompt and\nusers’ profiles. However, during real-world applications, the attacker and users usually have no access\nto the prompt *P*, which makes the prompt attack infeasible. Therefore, in this paper, we only use",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 203,
    "content": "CheatAgent to generate item perturbations and insert them into the user’s history interactions.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 204,
    "content": "**5.1.4** **Baselines.**\n\nSeveral baselines are utilized to investigate the defense performance of different methods:\n\n- **RD** [ 76 ] randomly deletes some items within the users’ historical sequences to filter out the\nadversarial perturbations.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 205,
    "content": "- **PD** [ 23 ] computes the perplexity for each item and filters out the item with high perplexity for\ndefense.\n\n- **RPD** [ 23 ] uses an LLM [ 57 ] to paraphrase the input prompt, which is widely used as the safeguard\nfor LLMs.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 206,
    "content": "- **RTD** [ 23 ] retokenizes the input prompt, which aims to break tokens apart and disrupt adversarial\nbehaviors.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 207,
    "content": "- **LLMSI** [ 56 ] provides a safety instruction, i.e., \"Please take into account the noise present in\nthe user’s historical interactions and filter them\", along with the input prompt to guide the LLMempowered RecSys to defense adversarial attacks by themselves.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 208,
    "content": "- **RDE** [ 6 ] randomly deletes some items within the users’ interaction sequences and generates\nmultiple cleansed prompts. The final recommendations are obtained by majority voting [27].",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 209,
    "content": "- **ICL** [ 56 ] randomly retrieves several users with different historical sequences as the demonstrations\nand integrates the retrieved users’ profiles with the original prompt for recommendation.\n\n**5.1.5** **Implementation.**",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 210,
    "content": "The proposed RETURN and all baselines are implemented by Pytorch. All victim models (i.e., **P5**\nand **TALLRec** ) and the attacker algorithm (i.e., **CheatAgent** ) are implemented based on their official",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 211,
    "content": "codes. The training and test set are constructed according to the studies of Xu et al. [68] and Bao et al.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 212,
    "content": "[4] for P5 and TALLRec, respectively. We adopt CheatAgent to generate adversarial perturbations\nand insert them into the benign users’ interaction history of the test set to investigate the defense",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 213,
    "content": "performance of different methods. The magnitude of perturbations *△* is set to 3, consistent with the\nstudy of Ning et al. [45] . For the proposed RETURN, we directly use the training set as the external",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 214,
    "content": "database. During the recommendation generation process, *m* = 10 is set as default, meaning that\nthe final ensemble recommendation is obtained based on these 10 purified prompts. For RD, we\nrandomly delete 3 items and generate recommendations. For PD, we select the top 3 items with",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 215,
    "content": "11\n\n\n-----",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 216,
    "content": "the highest perplexity as the perturbations and delete these items for recommendations. For RTD,\nwe adopt the BPE-dropout [ 49 ] to tokenize the input query to mitigate the impact of adversarial\nperturbations. RDE generates 10 purified prompts and integrates their recommendation outcomes",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 217,
    "content": "as the final prediction. ICL randomly retrieves 5 users’ interaction sequences from the external\ndatabase and integrates them with the original input for recommendations. All random seeds were\nfixed throughout the experiments, consistent with the used victim RecSys P5 [ 18 ] and TALLRec [ 4 ].",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 218,
    "content": "This ensures that the experimental results are reproducible, and therefore, we do not include variance\nin the reported results.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 219,
    "content": "**5.1.6** **Evaluation Metrics.**",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 220,
    "content": "For **P5** model, Top- *k* Hit Ratio ( **H@** *k* ) and Normalized Discounted Cumulative Gain (NDCG)\n( **N@** *k* ) [ 18 ] are employed to evaluate the recommendation performance. In this paper, we set *k* = 5",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 221,
    "content": "and *k* = 10, respectively. **A-H@** *k* and **A-N@** *k* represent the extent of the decrease in H@ *k* and\nN@ *k* after inserting adversarial perturbations into the benign prompt, which are used to measure the\nattack performance [45], formulated as:",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 222,
    "content": "� �\nH@ *k* N@ *k*\nA-H@ *k* = 1 *−* (14)\nH@ *k* *[,]* [ A-N][@] *[k]* [ = 1] *[ −]* N@ *k* *[,]*",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 223,
    "content": "where H [�] @ *k* and N [�] @ *k* evaluate the recommendation performance of the victim model when it is under\nattack. **D-H@** *k* and **D-N@** *k* are utilized to evaluate the performance of defense algorithms, which\nrepresent the decrease ratio in A-H@ *k* and A-N@ *k*, defined as:",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 224,
    "content": "� �\nA-H@ *k* A-N@ *k*\nD-H@ *k* = (15)\nA-H@ *k* *[−]* [1] *[,]* [ D-N][@] *[k]* [ =] A-N@ *k* *[−]* [1] *[,]*",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 225,
    "content": "where A-H [�] @ *k* and A-N [�] @ *k* represent the attack performance when adversarial examples are processed by defense algorithms. A greater decrease in A-H@ *k* and A-N@ *k* indicates reduced attack",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 226,
    "content": "performance and improved performance of the defense methods. For **TALLRec** model, we utilize the\nArea Under the Receiver Operating Characteristic (AUC) to assess the recommendation performance,\nwhich is consistent with the study of Bao et al. [4] . ASR-A and D-A [ 45 ] are employed to evaluate",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 227,
    "content": "the performance of the attack and defense methods, defined as:",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 228,
    "content": "� �\nAUC ASR-A\nASR-A = 1 *−* (16)\nAUC *[,]* [ D-A][ =] ASR-A *[−]* [1] *[,]*\n\nwhere AUC [�] and ASR-A [�] represent the AUC when the input contains perturbations and when the input\nis purified by the defense methods, respectively.\n\n**5.2** **Defense Effectiveness**",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 229,
    "content": "In this subsection, we investigate the defense performance of different methods. The results based on\n**P5** with different indexing methods are summarised in Table 1 and Table 2, and the results based on",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 230,
    "content": "**TALLRec** are shown in Figure 3. Benign denotes the use of the original prompt without perturbations\nfor recommendations, and CheatAgent represents the recommendation performance under attacks.\nBased on these experiments, some insights are obtained as follows:",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 231,
    "content": "- As shown in Table 1 and Table 2, the recommendation performance increases after deleting high\nperplexity items using PD. However, the effectiveness of this method is not robust. For instance,\non the ML1M dataset, PD can significantly enhance the recommendation performance of RecSys",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 232,
    "content": "under attacks. While on the Taobao dataset, the defense performance of PD is limited.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 233,
    "content": "- RPD and RTD, two common defense methods for LLMs, cannot achieve the desired performance\nfor LLM-empowered RecSys in most cases. The reason is that LLM-empowered RecSys have\ncaptured the domain-specific knowledge of recommendations (e.g., the meaning of item IDs and",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 234,
    "content": "item relationships) during the training process. However, the LLMs employed by RPD struggle to\nunderstand item IDs, making it challenging to effectively rewrite the input prompt. Additionally,\nRTD disrupts the item ID structure, which further degrades recommendation performance.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 235,
    "content": "12\n\n\n-----\n\nTable 1: Defense p erformance of different methods ( Victim model: P5, Indexin g : Se q uential )\n\n**Datasets** **Methods** **H@5↑** **H@10↑** **N@5↑** **N@10↑** **A-H@5↓** **A-H@10↓** **A-N@5↓** **A-N@10↓** **D-H@5↑** **D-H@10↑** **D-N@5↑** **D-N@10↑**",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 236,
    "content": "Benign 0.2116 0.3055 0.1436 0.1737 / / / / / / / /\nCheatAgent 0.0646 0.1171 0.0405 0.0573 0.6948 0.6168 0.7181 0.6699 0.0000 0.0000 0.0000 0.0000\n\nPD 0.1303 0.1935 0.0851 0.1053 0.3842 0.3664 0.4077 0.3939 0.4471 0.4060 0.4323 0.4120",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 237,
    "content": "RPD 0.0627 0.1070 0.0389 0.0530 0.7034 0.6499 0.7291 0.6950 -0.0124 -0.0536 -0.0153 -0.0374\n\nRTD 0.0093 0.0161 0.0060 0.0082 0.9562 0.9474 0.9579 0.9527 -0.3761 -0.5360 -0.3340 -0.4222\n\n**ML1M** RD 0.0969 0.1526 0.0620 0.0799 0.5423 0.5003 0.5680 0.5400 0.2196 0.1889 0.2090 0.1940",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 238,
    "content": "LLMSI 0.0624 0.1073 0.0398 0.0542 0.7050 0.6488 0.7227 0.6878 -0.0146 -0.0518 -0.0064 -0.0267\n\nICL 0.0546 0.0858 0.0348 0.0449 0.7418 0.7192 0.7574 0.7418 -0.0676 -0.1661 -0.0547 -0.1073\n\nRDE 0.0924 0.1566 0.0581 0.0786 0.5634 0.4873 0.5951 0.5475 0.1892 0.2100 0.1712 0.1827",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 239,
    "content": "RETURN **0.1384** **0.2091** **0.0915** **0.1142** **0.3459** **0.3154** **0.3630** **0.3427** **0.5023** **0.4886** **0.4945** **0.4885**\n\nBenign 0.0404 0.0606 0.0265 0.0331 / / / / / / / /\nCheatAgent 0.0138 0.0239 0.0084 0.0117 0.6591 0.6061 0.6820 0.6471 0.0000 0.0000 0.0000 0.0000",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 240,
    "content": "PD 0.0183 0.0330 0.0124 0.0170 0.5455 0.4545 0.5331 0.4851 0.1724 0.2500 0.2183 0.2503\n\nRPD 0.0183 0.0312 0.0106 0.0147 0.5455 0.4848 0.6006 0.5556 0.1724 0.2000 0.1193 0.1413\n\nRTD 0.0046 0.0110 0.0024 0.0043 0.8864 0.8182 0.9108 0.8691 -0.3448 -0.3500 -0.3355 -0.3430",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 241,
    "content": "**LastFM** RD 0.0220 0.0303 0.0139 0.0165 0.4545 0.5000 0.4743 0.5010 0.3103 0.1750 0.3045 0.2258\n\nLLMSI 0.0119 0.0229 0.0080 0.0116 0.7045 0.6212 0.7003 0.6491 -0.0690 -0.0250 -0.0269 -0.0031\n\nICL 0.0174 0.0321 0.0113 0.0160 0.5682 0.4697 0.5726 0.5172 0.1379 0.2250 0.1604 0.2007",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 242,
    "content": "RDE 0.0220 0.0339 0.0128 0.0167 0.4545 0.4394 0.5170 0.4960 0.3103 0.2750 0.2420 0.2334\n\nRETURN **0.0266** **0.0385** **0.0169** **0.0207** **0.3409** **0.3636** **0.3613** **0.3731** **0.4828** **0.4000** **0.4703** **0.4234**",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 243,
    "content": "Benign 0.1420 0.1704 0.1100 0.1191 / / / / / / / /\nCheatAgent 0.0863 0.1099 0.0615 0.0690 0.3922 0.3548 0.4409 0.4207 0.0000 0.0000 0.0000 0.0000\n\nPD 0.0935 0.1153 0.0687 0.0758 0.3414 0.3231 0.3752 0.3638 0.1294 0.0894 0.1490 0.1352",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 244,
    "content": "RPD 0.0811 0.1027 0.0567 0.0637 0.4291 0.3971 0.4845 0.4657 -0.0941 -0.1192 -0.0989 -0.1069\n\nRTD 0.0016 0.0044 0.0010 0.0019 0.9885 0.9740 0.9908 0.9840 -1.5206 -1.7453 -1.2470 -1.3390\n\n**Taobao** RD 0.0886 0.1121 0.0650 0.0726 0.3760 0.3423 0.4087 0.3905 0.0412 0.0352 0.0731 0.0718",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 245,
    "content": "LLMSI 0.0867 0.1112 0.0615 0.0694 0.3899 0.3471 0.4408 0.4176 0.0059 0.0217 0.0002 0.0073\n\nICL 0.0557 0.0734 0.0385 0.0442 0.6078 0.5692 0.6502 0.6287 -0.5500 -0.6043 -0.4747 -0.4944\n\nRDE 0.0855 0.1217 0.0626 0.0742 0.3979 0.2856 0.4305 0.3770 -0.0147 0.1951 0.0236 0.1038",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 246,
    "content": "RETURN **0.1124** **0.1384** **0.0890** **0.0975** **0.2088** **0.1875** **0.1904** **0.1817** **0.4676** **0.4715** **0.5682** **0.5680**\n\nTable 2: Defense p erformance of different methods ( Victim model: P5, Indexin g : Random )",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 247,
    "content": "**Datasets** **Methods** **H@5↑** **H@10↑** **N@5↑** **N@10↑** **A-H@5↓** **A-H@10↓** **A-N@5↓** **A-N@10↓** **D-H@5↑** **D-H@10↑** **D-N@5↑** **D-N@10↑**",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 248,
    "content": "Benign 0.1058 0.1533 0.0693 0.0847 / / / / / / / /\nCheatAgent 0.0421 0.0689 0.0262 0.0348 0.6025 0.5508 0.6221 0.5890 0.0000 0.0000 0.0000 0.0000\n\nPD 0.0626 0.0959 0.0407 0.0514 0.4085 0.3747 0.4127 0.3924 0.3221 0.3196 0.3365 0.3338",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 249,
    "content": "RPD 0.0439 0.0717 0.0280 0.0370 0.5853 0.5324 0.5958 0.5634 0.0286 0.0333 0.0423 0.0435\n\nRTD 0.0121 0.0217 0.0076 0.0106 0.8858 0.8585 0.8910 0.8745 -0.4701 -0.5588 -0.4323 -0.4847\n\n**ML1M** RD 0.0425 0.0657 0.0281 0.0355 0.5978 0.5713 0.5950 0.5802 0.0078 -0.0373 0.0435 0.0150",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 250,
    "content": "LLMSI 0.0442 0.0695 0.0271 0.0353 0.5822 0.5464 0.6089 0.5832 0.0338 0.0078 0.0212 0.0099\n\nICL 0.0336 0.0535 0.0214 0.0278 0.6823 0.6512 0.6914 0.6721 -0.1325 -0.1824 -0.1115 -0.1411\n\nRDE 0.0493 0.0800 0.0303 0.0401 0.5336 0.4784 0.5631 0.5268 0.1143 0.1314 0.0949 0.1057",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 251,
    "content": "RETURN **0.0929** **0.1377** **0.0604** **0.0750** **0.1221** **0.1015** **0.1276** **0.1147** **0.7974** **0.8157** **0.7949** **0.8053**\n\nBenign 0.0128 0.0248 0.0072 0.0110 / / / / / / / /\nCheatAgent 0.0101 0.0220 0.0055 0.0094 0.2143 0.1111 0.2258 0.1474 0.0000 0.0000 0.0000 0.0000",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 252,
    "content": "PD **0.0174** **0.0294** **0.0102** **0.0139** **-0.3571** **-0.1852** **-0.4227** **-0.2609** **2.6667** **2.6667** **2.8719** **2.7708**\n\nRPD 0.0128 0.0202 0.0080 0.0104 0.0000 0.1852 -0.1203 0.0566 1.0000 -0.6667 1.5326 0.6156",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 253,
    "content": "RTD 0.0128 0.0193 0.0074 0.0095 0.0000 0.2222 -0.0392 0.1365 1.0000 -1.0000 1.1735 0.0738\n\n**LastFM** RD 0.0110 0.0229 0.0062 0.0101 0.1429 0.0741 0.1281 0.0808 0.3333 0.3333 0.4327 0.4517\n\nLLMSI 0.0101 0.0220 0.0054 0.0093 0.2143 0.1111 0.2451 0.1537 0.0000 0.0000 -0.0854 -0.0429",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 254,
    "content": "ICL 0.0073 0.0138 0.0045 0.0066 0.4286 0.4444 0.3746 0.4022 -1.0000 -3.0000 -0.6587 -1.7294\n\nRDE 0.0110 0.0266 0.0073 0.0123 0.1429 -0.0741 -0.0161 -0.1204 0.3333 1.6667 1.0713 1.8173\n\nRETURN 0.0138 0.0220 0.0067 0.0093 -0.0714 0.1111 0.0692 0.1531 1.3333 0.0000 0.6937 -0.0392",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 255,
    "content": "Benign 0.1643 0.1804 0.1277 0.1330 / / / / / / / /\nCheatAgent 0.1012 0.1217 0.0682 0.0749 0.3838 0.3252 0.4661 0.4367 0.0000 0.0000 0.0000 0.0000\n\nPD 0.1042 0.1184 0.0725 0.0771 0.3659 0.3433 0.4327 0.4199 0.0468 -0.0559 0.0717 0.0384",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 256,
    "content": "RPD 0.0945 0.1112 0.0640 0.0694 0.4247 0.3833 0.4992 0.4778 -0.1065 -0.1788 -0.0709 -0.0942\n\nRTD 0.0118 0.0190 0.0073 0.0097 0.9282 0.8946 0.9425 0.9273 -1.4182 -1.7514 -1.0220 -1.1234\n\n**Taobao** RD 0.1094 0.1237 0.0774 0.0820 0.3340 0.3143 0.3941 0.3833 0.1299 0.0335 0.1544 0.1223",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 257,
    "content": "LLMSI 0.1022 0.1237 0.0684 0.0754 0.3779 0.3143 0.4646 0.4331 0.0156 0.0335 0.0032 0.0082\n\nICL 0.0655 0.0799 0.0465 0.0511 0.6012 0.5568 0.6360 0.6155 -0.5662 -0.7123 -0.3644 -0.4094\n\nRDE 0.1094 0.1479 0.0793 0.0918 0.3340 0.1798 0.3792 0.3101 0.1299 0.4469 0.1865 0.2899",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 258,
    "content": "RETURN **0.1317** **0.1537** **0.1055** **0.1126** **0.1984** **0.1480** **0.1741** **0.1532** **0.4831** **0.5447** **0.6266** **0.6491**",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 259,
    "content": "- Adversarial perturbations are typically carefully crafted, so disrupting any component may reduce\nthe attack’s effectiveness. Therefore, randomly removing a few items from the user’s interaction\nhistory (i.e., RD) can improve the robustness of the LLM-powered RecSys. Furthermore, RDE",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 260,
    "content": "generally outperforms RD, suggesting that an ensemble strategy can further enhance system\nrobustness.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 261,
    "content": "- The proposed RETURN outperforms all other baselines on three datasets and significantly improves\nthe recommendation performance even under attacks, demonstrating the potential of introducing\ncollaborative knowledge from external databases. For example, on the Taobao dataset, CheatAgent",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 262,
    "content": "reduces the H@5 from 0.1420 to 0.0863. By introducing collaborative knowledge for input purification, RETURN raises the H@5 to 0.1124, nearly approaching the recommendation performance\nof using benign prompts, which fully demonstrates the effectiveness of RETURN.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 263,
    "content": "- TALLRec uses item titles to construct the input prompt, which has distinct inherent mechanisms\nwith P5. As shown in Figure 3, the proposed RETURN also dramatically increases the AUC of\nTALLRec and decreases the attack performance, demonstrating the robustness of RETURN to the",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 264,
    "content": "architecture of the LLM-empowered RecSys.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 265,
    "content": "13\n\n\n-----\n\n|Col1|Col2|Col3|Col4|Col5|Col6|Col7|Col8|Col9|\n|---|---|---|---|---|---|---|---|---|\n||||||||||\n||||||||||\n||||||||||\n||||||||||\n||||||||||",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 266,
    "content": "|Col1|Col2|Col3|Col4|Col5|Col6|Col7|Col8|Col9|\n|---|---|---|---|---|---|---|---|---|\n||||||||||\n||||||||||\n||||||||||\n||||||||||\n||||(a) A|UC||F|igu||",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 267,
    "content": "|Benign CheatAgent PD RPD RTD RD LLMSI ICL RDE RETURN 0.7 0.5 60 0.6 0.4 50 0.5 0.3 40 0.4 0.2 30 0.3 0.1 20 0.2 0.0 10 (a) AUC (b) ASR-A (c) D-A (%) Figure 3: Defense Performance on TALLRec Table 3: The defense performance of the proposed RETURN with respect to different attack",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 268,
    "content": "proposed RETURN with respect to different attack methods|Col2|Col3|Col4|Col5|Col6|Col7|Col8|Col9|Col10|Col11|",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 269,
    "content": "|---|---|---|---|---|---|---|---|---|---|---|\n||||||||||||\n||||||||||||\n||||||||||||\n||||||||||||\n||||||||||||\n|||||(c|) D-A (||%)||||\n|||||||nt a|||||\n|Methods H@5 H@10 N@5 N@10 A-H@5 A-H@10 A-N@5 A-N@10 D-H@5 D-H@10|||||||D-N@5 D-N@10||||",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 270,
    "content": "Benign 0.0404 0.0606 0.0265 0.0331 / / / / / / / /\n\nPA 0.0064 0.0147 0.0032 0.0060 0.8409 0.7576 0.8777 0.8187 0.0000 0.0000 0.0000 0.0000\n\nRETURN 0.0248 0.0376 0.0148 0.0189 0.3864 0.3788 0.4423 0.4280 0.5405 0.5000 0.4961 0.4772",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 271,
    "content": "RA 0.0376 0.0587 0.0251 0.0317 0.0682 0.0303 0.0540 0.0405 0.0000 0.0000 0.0000 0.0000\n\nRETURN 0.0394 0.0587 0.0257 0.0318 0.0227 0.0303 0.0326 0.0377 0.6667 0.0000 0.3957 0.0679",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 272,
    "content": "CheatAgent 0.0138 0.0239 0.0084 0.0117 0.6591 0.6061 0.6820 0.6471 0.0000 0.0000 0.0000 0.0000\nRETURN 0.0266 0.0385 0.0169 0.0207 0.3409 0.3636 0.3613 0.3731 0.4828 0.4000 0.4703 0.4234\n\n**5.3** **Model Analysis**",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 273,
    "content": "**5.3** **Model Analysis**\n\n**5.3.1** **Attack Scenarios: Clickbait and vulnerabilities of LLM-empowered RecSys.**",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 274,
    "content": "The attack discussed in this paper mirrors a real-world phenomenon, commonly known as clickbait [ 72, 61 ]. Clickbait refers to the scenario in which attackers might post products with enticing\nimages and titles to attract user clicks on an e-commerce platform. Users are easily drawn to these",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 275,
    "content": "clickbait products and interact with them, even though the content of these goods may not truly\nalign with their preferences [ 72, 61 ]. However, existing studies [ 45 ] have demonstrated that LLMempowered RecSys is vulnerable to minor perturbations in user historical interactions. If users are",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 276,
    "content": "attracted by clickbait products and engage with them, minor perturbations will be introduced to their\nhistorical interactions. Such minor perturbations (e.g., irrelevant items) can easily lead the LLMempowered RecSys to misunderstand the user preferences by capturing the collaborative knowledge",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 277,
    "content": "from the user’s historical interactions. This leads to inaccurate recommendations, affecting user\nexperience and engagement and consequently diminishing company profits. Therefore, enhancing\nthe robustness of the LLM-empowered RecSys is crucial to mitigate the clickbait issue, which is a",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 278,
    "content": "practical necessity.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 279,
    "content": "During experiments, to simulate the worst-case scenario, we adopt CheatAgent [ 45 ], which is\na powerful attacker, to insert perturbations to the user’s historical sequences. Besides, we also\nemploy various attack methods and perturbation intensities to simulate the scenario in which the",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 280,
    "content": "user’s historical interactions contain minor perturbations. We adopt two other methods to generate\nadversarial perturbations: PA [69] adopts an LLM to generate perturbations, and RA [45] randomly\nselects the items from the item pool as the perturbations.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 281,
    "content": "As shown in Table 3, we can observe that the proposed defense method significantly reduces the\neffectiveness of various attack methods (i.e., CheatAgent, PA). This implies that even if users\ninteract with clickbait items that trigger vulnerabilities in the recommendation system, the proposed",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 282,
    "content": "RETURN method can effectively cleanse these malicious disturbances, ensuring the correctness of\nrecommendations. Regarding RA, its attack capability is constrained, and it is aimed at simulating\nscenarios where perturbation items do not cause the RecSys to misinterpret user preferences. In",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 283,
    "content": "this case, RETURN still improves or maintains the recommendation performance of the RecSys.\nThis demonstrates the robustness of the proposed RETURN against different attack intensities and\nscenarios.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 284,
    "content": "**5.3.2** **Ablation Study**",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 285,
    "content": "Three variants **RETURN-ROP**, **RETURN-RR**, and **RETURN-w/o Ens** are employed for comparison: 1) **RETURN-ROP** randomly creates the collaborative item graphs to demonstrate the\neffectiveness and importance of introducing the external database. 2) **RETURN-RR** directly deletes\n\n14\n\n\n-----",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 286,
    "content": "14\n\n\n-----\n\nTable 4: Com p arison between RETURN and its variants on three datasets\n\n**Datasets** **Methods** **H@5↑** **H@10↑** **N@5↑** **N@10↑** **A-H@5↓** **A-H@10↓** **A-N@5↓** **A-N@10↓** **D-H@5↑** **D-H@10↑** **D-N@5↑** **D-N@10↑**",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 287,
    "content": "Benign 0.2116 0.3055 0.1436 0.1737 / / / /\nCheatAgent 0.0646 0.1171 0.0405 0.0573 0.6948 0.6168 0.7181 0.6699 0.0000 0.0000 0.0000 0.0000\n\n**ML1M** RETURN **0.1384** **0.2091** **0.0915** **0.1142** **0.3459** **0.3154** **0.3630** **0.3427** **0.5023** **0.4886** **0.4945** **0.4885**",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 288,
    "content": "–ROP 0.0747 0.1286 0.0467 0.0639 0.6471 0.5789 0.6747 0.6321 0.0687 0.0615 0.0604 0.0564\n\n–RR 0.1093 0.1705 0.0701 0.0898 0.4836 0.4417 0.5119 0.4831 0.3041 0.2838 0.2872 0.2788\n\n–w/o Ens 0.1185 0.1889 0.0783 0.1010 0.4397 0.3816 0.4546 0.4184 0.3671 0.3814 0.3670 0.3754",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 289,
    "content": "Benign 0.0404 0.0606 0.0265 0.0331 / / / /\nCheatAgent 0.0138 0.0239 0.0084 0.0117 0.6591 0.6061 0.6820 0.6471 0.0000 0.0000 0.0000 0.0000\n\n**LastFM** RETURN **0.0266** **0.0385** **0.0169** **0.0207** **0.3409** **0.3636** **0.3613** **0.3731** **0.4828** **0.4000** **0.4703** **0.4234**",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 290,
    "content": "–ROP 0.0165 0.0321 0.0115 0.0164 0.5909 0.4697 0.5683 0.5044 0.1034 0.2250 0.1667 0.2205\n\n–RR 0.0248 0.0339 0.0147 0.0176 0.3864 0.4394 0.4466 0.4674 0.4138 0.2750 0.3452 0.2778\n\n–w/o Ens 0.0248 0.0367 0.0151 0.0188 0.3864 0.3939 0.4304 0.4309 0.4138 0.3500 0.3689 0.3342",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 291,
    "content": "Benign 0.1420 0.1704 0.1100 0.1191 / / / /\nCheatAgent 0.0863 0.1099 0.0615 0.0690 0.3922 0.3548 0.4409 0.4207 0.0000 0.0000 0.0000 0.0000\n\n**Taobao** RETURN **0.1124** **0.1384** **0.0890** **0.0975** **0.2088** **0.1875** **0.1904** **0.1817** **0.4676** **0.4715** **0.5682** **0.5680**",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 292,
    "content": "–ROP 0.1008 0.1222 0.0749 0.0819 0.2907 0.2827 0.3185 0.3126 0.2588 0.2033 0.2776 0.2570\n\n–RR 0.1122 0.1376 0.0882 0.0964 0.2099 0.1923 0.1981 0.1911 0.4647 0.4580 0.5508 0.5457\n\n–w/o Ens 0.1006 0.1250 0.0765 0.0843 0.2918 0.2663 0.3046 0.2925 0.2559 0.2493 0.3093 0.3048\n\n\n0.05\n\n0.04\n\n0.03\n\n0.02",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 293,
    "content": "0.05\n\n0.04\n\n0.03\n\n0.02\n\n0.00\n\n|Col1|Col2|Col3|Col4|\n|---|---|---|---|\n|||||\n|H@5 H@10 N@5 N@10||||\n\n5 10 15 20 25\n\n(a) H@ *k* and N@ *k* w.r.t. *m*\n\n\n20\n\n|Col1|Col2|Col3|D-H@5 D-H@10 D-N@5|\n|---|---|---|---|\n||||D-N@10|\n|||||\n\n5 10 15 20 25\n\n(b) D-H@ *k* and D-N@ *k* w.r.t. *m*\n\n\n70\n\n60\n\n50\n\n40",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 294,
    "content": "70\n\n60\n\n50\n\n40\n\n30\n\n\n\nFigure 4: Effect of the hyper-parameters *m* .",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 295,
    "content": "all items with low occurrence probabilities. 3) **RETURN-w/o Ens** generates recommendations\nwithout using the ensemble strategy and only creates one purified prompt by processing a fixed\nnumber of items. The results are summarised in Table 4. RETURN-ROP generates recommendations",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 296,
    "content": "without constructing collaborative item graphs from the external database, resulting in a significant\ndecrease in its defense performance. This highlights the importance of introducing accurate collaborative knowledge from the external database. Since directly deleting all items with low occurrence",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 297,
    "content": "probabilities may result in the RecSys failing to capture users’ preferences effectively, especially\nfor users with limited interactions, there is a significant decrease in the defense performance of\nRETURN-RR, illustrating the importance of employing the retrieval-augmented denoising strategy.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 298,
    "content": "Since the number of the perturbations is unknown, RETURN-w/o Ens fixes the number of purification\nitems. This approach usually leads to information loss if an excessive number of items are deleted, or",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 299,
    "content": "incomplete purification if not all perturbations are eliminated, demonstrating the importance of the\nrobust ensemble recommendation strategy.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 300,
    "content": "**5.3.3** **Parameter Analysis**",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 301,
    "content": "We investigate the sensitivity of RETURN to the hyperparameter *m* . We sample varying values for\n*m* and test the defense performance of the proposed method. and the results are illustrated in Figure 4.\nWe observe that as *m* increases, the recommendation performance and the defense capability of",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 302,
    "content": "RETURN fluctuate within a small range, demonstrating the robustness of the proposed method to\nhyperparameters.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 303,
    "content": "**5.3.4** **The Robustness to the Perturbation Intensity**",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 304,
    "content": "In this subsection, we investigate the robustness of RETURN to the perturbation intensity *△* . We\ninsert varying numbers of perturbations into benign users and evaluate the defense performance\nof the proposed method. As shown in Table 5, the proposed method significantly enhances the",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 305,
    "content": "recommendation performance of LLM-empowered RecSys regardless of the number of perturbations\ninserted into the input. This is attributed to robust recommendation generation strategies that avoid\nintroducing fixed thresholds, thereby improving the robustness of the proposed RETURN to the",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 306,
    "content": "number of perturbations.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 307,
    "content": "15\n\n\n-----\n\nTable 5: The defense p erformance of RETURN with res p ect to the p erturbation intensit y *△*\n\n**Methods** **H@5↑** **H@10↑** **N@5↑** **N@10↑** **A-H@5↓** **A-H@10↓** **A-N@5↓** **A-N@10↓** **D-H@5↑** **D-H@10↑** **D-N@5↑** **D-N@10↑**",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 308,
    "content": "Benign 0.0404 0.0606 0.0265 0.0331 / / / / / / / /\n\n*△* =1 0.0183 0.0394 0.0122 0.0190 0.5455 0.3485 0.5390 0.4265 0.0000 0.0000 0.0000 0.0000\n\nRETURN 0.0303 0.0486 0.0208 0.0265 0.2500 0.1970 0.2149 0.1974 0.5417 0.4348 0.6013 0.5373",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 309,
    "content": "*△* =2 0.0138 0.0257 0.0090 0.0128 0.6591 0.5758 0.6621 0.6120 0.0000 0.0000 0.0000 0.0000\n\nRETURN 0.0248 0.0367 0.0148 0.0185 0.3864 0.3939 0.4432 0.4406 0.4138 0.3158 0.3307 0.2801\n\n*△* =3 0.0138 0.0239 0.0084 0.0117 0.6591 0.6061 0.6820 0.6471 0.0000 0.0000 0.0000 0.0000",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 310,
    "content": "RETURN 0.0266 0.0385 0.0169 0.0207 0.3409 0.3636 0.3613 0.3731 0.4828 0.4000 0.4703 0.4234\n\n*△* =4 0.0119 0.0202 0.0082 0.0109 0.7045 0.6667 0.6893 0.6704 0.0000 0.0000 0.0000 0.0000\n\nRETURN 0.0248 0.0349 0.0162 0.0194 0.3864 0.4242 0.3879 0.4146 0.4516 0.3636 0.4372 0.3816",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 311,
    "content": "*△* =5 0.0119 0.0211 0.0068 0.0098 0.7045 0.6515 0.7425 0.7048 0.0000 0.0000 0.0000 0.0000\n\nRETURN 0.0211 0.0284 0.0149 0.0173 0.4773 0.5303 0.4385 0.4771 0.3226 0.1860 0.4094 0.3231\n\n**5.3.5** **Impact on Benign Users**",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 312,
    "content": "It is crucial that defense algorithms should not affect the recommendation performance of RecSys\nfor users whose interaction histories contain no perturbations. Therefore, in this subsection, the\nimpact of RETURN on benign users is investigated, and the results are shown in Table 6. We can",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 313,
    "content": "observe that if the users’ profiles consist of no perturbations, RETURN can almost maintain the\nrecommendation performance even though RETURN deletes or replaces some items. Note that\nthe deletion or replacement operations are implemented based on the collaborative co-occurrence",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 314,
    "content": "frequency, indicating that the selected items usually fail to align with the users’ preferences. Therefore,\nRETURN has little impact on the recommendation effectiveness for benign users, which demonstrates\nits practical applicability in enhancing the robustness of LLM-empowered RecSys.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 315,
    "content": "Table 6: Recommendation p erformance when users’ p rofiles contain no p erturbation\n\n**Indexing** **Datasets** **Methods** **H@5↑** **H@10↑** **N@5↑** **N@10↑**\n\nBenign 0.2116 0.3055 0.1436 0.1737\nML1M RETURN 0.1675 0.2498 0.1131 0.1397\n\nBenign 0.0404 0.0606 0.0265 0.0331",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 316,
    "content": "Benign 0.0404 0.0606 0.0265 0.0331\n\n**Sequential** LastFM RETURN 0.0376 0.0569 0.0232 0.0293\n\nBenign 0.1420 0.1704 0.1100 0.1191\nTaobao RETURN 0.1006 0.1250 0.0765 0.0843\n\nBenign 0.1058 0.1533 0.0693 0.0847\nML1M RETURN 0.0944 0.1406 0.0611 0.0760\n\nBenign 0.0128 0.0248 0.0072 0.0110",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 317,
    "content": "Benign 0.0128 0.0248 0.0072 0.0110\n\n**Random** LastFM RETURN 0.0156 0.0284 0.0094 0.0136\n\nBenign 0.1643 0.1804 0.1277 0.1330\nTaobao RETURN 0.1239 0.1409 0.0893 0.0948\n\n**5.3.6** **Time Complexity**",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 318,
    "content": "To address the concern regarding the computational overhead introduced by the RETURN framework,\nwe conduct additional experiments to analyse the time complexity of RETURN. We measure the\naverage time taken by the LLM-empowered RecSys to generate recommendations after incorporating",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 319,
    "content": "different defense methods on the LastFM dataset. As shown in Tabel 7, we can observe that\nmethods requiring minimal computational resources (e.g., RD, LLMSI, etc.) exhibit significantly\nshorter recommendation generation times, typically less than 0.5 seconds. However, their defense",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 320,
    "content": "performance is notably limited. In contrast, more powerful methods, including RETURN, exhibit\nslightly longer recommendation generation times, with RETURN taking approximately 0.8599\nseconds. This is comparable to other advanced defense methods like PD (0.7314 seconds) and RDE",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 321,
    "content": "(0.7222 seconds), which also take around 1 second.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 322,
    "content": "The results indicate that while RETURN introduces additional computational steps, such as voting\noperations, it does not significantly increase the overall computational burden of the RecSys. Importantly, RETURN achieves this while substantially enhancing the robustness of RecSys against",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 323,
    "content": "perturbations. Thus, the framework strikes a balance between computational efficiency and defense\neffectiveness, making it a practical choice for real-world applications.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 324,
    "content": "16\n\n\n-----\n\nTable 7: Com p utational time of different methods\n\n**Methods** **PD** **RPD** **RTD** **RD** **LLMSI** **ICL** **RDE** **RETURN**\n\n**Time (s)** 0.7314 1.2271 0.2916 0.3036 0.3006 0.3130 0.7222 0.8599\n\n**5.3.7** **Impact of Poor Quality Data**",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 325,
    "content": "We conduct additional experiments to investigate the impact of data quality. We introduce two\nvariants: **RETURN-A-k** and **RETURN-D-k**, where perturbations are injected into or items are\ndeleted from the historical interactions of users in the external database to generate collaborative item",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 326,
    "content": "graphs. Here, *k* =0.15 and *k* =0.3 represent the proportion of perturbations or deletions, respectively.\nThe results are shown in Table 8. The results demonstrate that RETURN-A-k still achieves remarkable",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 327,
    "content": "defense performance even when perturbations are introduced into the external database. This is\nbecause the collaborative item graphs store co-occurrence frequencies, and minor perturbations\ndo not significantly alter the overall co-occurrence distribution among items. After normalization,",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 328,
    "content": "these perturbations have minimal impact on RETURN’s ability to cleanse user interaction data and\ngenerate accurate recommendations. Additionally, RETURN-D-k fails to achieve the desired defense\nperformance because the lack of sufficient collaborative signals prevents it from accurately capturing",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 329,
    "content": "relationships between items, thereby hindering its ability to identify perturbations.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 330,
    "content": "These experimental results indicate that the presence of noisy data in the external database (i.e.,\nlow-quality data) does not significantly deteriorate the performance of RETURN, as the co-occurrence",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 331,
    "content": "distribution remains relatively stable. However, insufficient data (e.g., due to deletions) can degrade\nRETURN’s defense effectiveness, as it relies on sufficient collaborative signals to accurately model",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 332,
    "content": "item relationships. Therefore, while RETURN is robust to minor data quality issues, ensuring an\nadequate volume of data is crucial for maintaining its performance.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 333,
    "content": "Table 8: The defense p erformance of RETURN with res p ect to different external databases\n\n**Methods** **H@5↑** **H@10↑** **N@5↑** **N@10↑** **A-H@5↓** **A-H@10↓** **A-N@5↓** **A-N@10↓** **D-H@5↑** **D-H@10↑** **D-N@5↑** **D-N@10↑**",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 334,
    "content": "Benign 0.0404 0.0606 0.0265 0.0331 / / / / / / / /\nCheatAgent 0.0138 0.0239 0.0084 0.0117 0.6591 0.6061 0.6820 0.6471 0.0000 0.0000 0.0000 0.0000\n\nPD 0.0183 0.0330 0.0124 0.0170 0.5455 0.4545 0.5331 0.4851 0.1724 0.2500 0.2183 0.2503",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 335,
    "content": "RPD 0.0183 0.0312 0.0106 0.0147 0.5455 0.4848 0.6006 0.5556 0.1724 0.2000 0.1193 0.1413\n\nRTD 0.0046 0.0110 0.0024 0.0043 0.8864 0.8182 0.9108 0.8691 -0.3448 -0.3500 -0.3355 -0.3430\n\nRD 0.0220 0.0303 0.0139 0.0165 0.4545 0.5000 0.4743 0.5010 0.3103 0.1750 0.3045 0.2258",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 336,
    "content": "LLMSI 0.0119 0.0229 0.0080 0.0116 0.7045 0.6212 0.7003 0.6491 -0.0690 -0.0250 -0.0269 -0.0031\n\nICL 0.0174 0.0321 0.0113 0.0160 0.5682 0.4697 0.5726 0.5172 0.1379 0.2250 0.1604 0.2007\n\nRDE 0.0220 0.0339 0.0128 0.0167 0.4545 0.4394 0.5170 0.4960 0.3103 0.2750 0.2420 0.2334",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 337,
    "content": "RETURN 0.0266 0.0385 0.0169 0.0207 0.3409 0.3636 0.3613 0.3731 0.4828 0.4000 0.4703 0.4234\n\nRETURN - A - 0.15 0.0294 0.0413 0.0180 0.0219 0.2727 0.3182 0.3208 0.3391 0.5862 0.4750 0.5296 0.4760\n\nRETURN - A - 0.3 0.0294 0.0440 0.0185 0.0232 0.2727 0.2727 0.3020 0.2980 0.5862 0.5500 0.5571 0.5395",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 338,
    "content": "RETURN - D - 0.15 0.0165 0.0321 0.0103 0.0152 0.5909 0.4697 0.6125 0.5409 0.1034 0.2250 0.1019 0.1642\n\nRETURN - D - 0.3 0.0165 0.0321 0.0103 0.0152 0.5909 0.4697 0.6125 0.5409 0.1034 0.2250 0.1019 0.1642\n\n**5.3.8** **The Adoption of Normal Distribution**",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 339,
    "content": "During the robust ensemble recommendation process, RETURN randomly samples an integer *n*\nfrom a normal distribution, and Top- *n* items with the lowest occurrence probabilities are identified\nfrom the user’s historical interactions for purification. The normal distribution is chosen because it",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 340,
    "content": "allows for better control over the strength of perturbation filtering in RETURN. If a majority of users’\ninteraction histories contain significant perturbations, making it difficult for RecSys to accurately",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 341,
    "content": "capture their preferences, the mean can be adjusted to enhance the purification strength of RETURN.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 342,
    "content": "During experiments, the mean and the variance are 3.5 and 0.5, respectively. Moreover, we conducted\nadditional experiments to demonstrate that RETURN is robust to the different values of mean\nand variance. The results are shown in Table 9. The performance of RETURN fluctuates within",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 343,
    "content": "a reasonable range as the mean and variance change, demonstrating its robustness to different\nparameter settings. This indicates that RETURN can adapt to varying distributions while maintaining\nits effectiveness in generating accurate recommendations.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 344,
    "content": "**5.3.9** **Impact on the Personalization of Recommendations**\n\nTo evaluate the impact of RETURN on personalized recommendations, we separately analyze the\nrecommendation results of the LLM-empowered RecSys for benign users and the results after\n\n17\n\n\n-----",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 345,
    "content": "17\n\n\n-----\n\nTable 9: The defense p erformance of RETURN with res p ect to different values of mean and variance\n\n**Methods** **H@5↑** **H@10↑** **N@5↑** **N@10↑** **A-H@5↓** **A-H@10↓** **A-N@5↓** **A-N@10↓** **D-H@5↑** **D-H@10↑** **D-N@5↑** **D-N@10↑**",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 346,
    "content": "Benign 0.0404 0.0606 0.0265 0.0331 / / / /\nCheatAgent 0.0138 0.0239 0.0084 0.0117 0.6591 0.6061 0.6820 0.6471 0.0000 0.0000 0.0000 0.0000\n\nPD 0.0183 0.0330 0.0124 0.0170 0.5455 0.4545 0.5331 0.4851 0.1724 0.2500 0.2183 0.2503",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 347,
    "content": "RPD 0.0183 0.0312 0.0106 0.0147 0.5455 0.4848 0.6006 0.5556 0.1724 0.2000 0.1193 0.1413\n\nRTD 0.0046 0.0110 0.0024 0.0043 0.8864 0.8182 0.9108 0.8691 -0.3448 -0.3500 -0.3355 -0.3430\n\nRD 0.0220 0.0303 0.0139 0.0165 0.4545 0.5000 0.4743 0.5010 0.3103 0.1750 0.3045 0.2258",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 348,
    "content": "LLMSI 0.0119 0.0229 0.0080 0.0116 0.7045 0.6212 0.7003 0.6491 -0.0690 -0.0250 -0.0269 -0.0031\n\nICL 0.0174 0.0321 0.0113 0.0160 0.5682 0.4697 0.5726 0.5172 0.1379 0.2250 0.1604 0.2007\n\nRDE 0.0220 0.0339 0.0128 0.0167 0.4545 0.4394 0.5170 0.4960 0.3103 0.2750 0.2420 0.2334",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 349,
    "content": "N(3.5, 0.5) 0.0266 0.0385 0.0169 0.0207 0.3409 0.3636 0.3613 0.3731 0.4828 0.4000 0.4703 0.4234\nN(3, 0.5) 0.0229 0.0358 0.0132 0.0173 0.4318 0.4091 0.5035 0.4766 0.3448 0.3250 0.2618 0.2635\nN(4, 0.5) 0.0267 0.0413 0.0174 0.0224 0.3389 0.3182 0.3449 0.3236 0.4859 0.4750 0.4943 0.4999",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 350,
    "content": "N(3.5, 1.0) 0.0229 0.0376 0.0150 0.0197 0.4318 0.3788 0.4362 0.4043 0.3448 0.3750 0.3604 0.3752\nN(3.5, 1.5) 0.0220 0.0367 0.0150 0.0198 0.4545 0.3939 0.4349 0.4025 0.3103 0.3500 0.3624 0.3780",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 351,
    "content": "introducing RETURN for denoising. We calculate the frequency of different items in both sets of\nresults, computed the Jaccard similarity coefficient [ 2 ] between the two distributions, determined the\nproportion of items that co-occurred, and measured the Shannon entropy of each distribution. The",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 352,
    "content": "results are presented in Table 10. Some observations can be obtained as follows:",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 353,
    "content": "- **Jaccard Similarity (0.7605):** The high Jaccard similarity coefficient indicates that the recommendation results before and after applying RETURN are highly consistent for benign users. This\nsuggests that RETURN preserves the majority of the original recommendations, although some",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 354,
    "content": "items are removed or replaced.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 355,
    "content": "- **Common Items Ratio (0.8706):** The proportion of items that co-occur in both the benign and\nRETURN-processed recommendations is 87.06%. This further demonstrates that RETURN\nmaintains the core set of recommended items, ensuring minimal disruption to the personalized\nrecommendations.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 356,
    "content": "- **Shannon Entropy:** The Shannon entropy values for both the benign (9.8616) and RETURNprocessed (9.8292) recommendations are nearly identical. This indicates that RETURN does not\nsignificantly reduce the diversity of the recommendations, preserving the richness and variety of",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 357,
    "content": "the suggested items.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 358,
    "content": "Table 10: Im p act of RETURN on the p ersonalization of recommendations\n\n|Col1|Shannon Entropy|Jaccard Similarity|Common Items Ratio|\n|---|---|---|---|\n|Benign RETURN|9.8616 9.8292|0.7605|0.8706|\n\n### **6 Conclusion**",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 359,
    "content": "In this paper, we propose a novel framework RETURN by retrieving collaborative knowledge from\nexternal databases to enhance the robustness of existing LLM-empowered RecSys in a plug-and-play\nmanner. Specifically, the proposed RETURN first converts the user interactions within external",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 360,
    "content": "databases into collaborative item graphs to implicitly encode the collaborative signals. Then, the\npotential perturbations are located by retrieving relevant knowledge from the generated graphs. To",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 361,
    "content": "mitigate the negative impact of perturbations and maintain the integrity of user preference, a retrievalaugmented denoising strategy is introduced to purify the input user profile. Finally, a robust ensemble",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 362,
    "content": "recommendation method is proposed to generate the final recommendations by adopting a decision\nfusion strategy. Comprehensive experiments on real-world datasets demonstrate the effectiveness of\nthe proposed RETURN and highlight the potential of introducing external collaborative knowledge",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 363,
    "content": "to enhance the robustness of LLM-empowered RecSys.\n### **References**",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 364,
    "content": "[1] Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni\nAleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, et al. Gpt-4\ntechnical report. *arXiv preprint arXiv:2303.08774*, 2023.\n\n18\n\n\n-----",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 365,
    "content": "18\n\n\n-----\n\n[2] Sujoy Bag, Sri Krishna Kumar, and Manoj Kumar Tiwari. An efficient recommendation\ngeneration using relevant jaccard similarity. *Information Sciences*, 483:53–64, 2019.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 366,
    "content": "[3] Tao Bai, Jinqi Luo, Jun Zhao, Bihan Wen, and Qian Wang. Recent advances in adversarial training for adversarial robustness. In *Proceedings of the Thirtieth International Joint Conference*\n*on Artificial Intelligence*, pages 4312–4321, 2021.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 367,
    "content": "[4] Keqin Bao, Jizhi Zhang, Yang Zhang, Wenjie Wang, Fuli Feng, and Xiangnan He. TALLRec:\nAn effective and efficient tuning framework to align large language model with recommendation.\nIn *ACM Conference on Recommender Systems*, 2023.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 368,
    "content": "[5] Qingpeng Cai, Zhenghai Xue, Chi Zhang, Wanqi Xue, Shuchang Liu, Ruohan Zhan, Xueliang\nWang, Tianyou Zuo, Wentao Xie, Dong Zheng, et al. Two-stage constrained actor-critic for\nshort video recommendation. In *Proceedings of the ACM Web Conference 2023*, pages 865–875,\n2023.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 369,
    "content": "[6] Bochuan Cao, Yuanpu Cao, Lu Lin, and Jinghui Chen. Defending against alignment-breaking\nattacks via robustly aligned LLM. In *Findings of the Association for Computational Linguistics*\n*ACL 2024*, 2024.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 370,
    "content": "[7] Jingfan Chen, Wenqi Fan, Guanghui Zhu, Xiangyu Zhao, Chunfeng Yuan, Qing Li, and Yihua\nHuang. Knowledge-enhanced black-box attacks for recommendations. In *Proceedings of the*\n*28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining*, pages 108–117,\n2022.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 371,
    "content": "[8] Luoxin Chen, Weitong Ruan, Xinyue Liu, and Jianhua Lu. SeqVAT: Virtual adversarial training\nfor semi-supervised sequence labeling. In *Proceedings of the 58th Annual Meeting of the*\n*Association for Computational Linguistics*, pages 8801–8811, 2020.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 372,
    "content": "[9] Paul Covington, Jay Adams, and Emre Sargin. Deep neural networks for Youtube recommendations. In *Proceedings of the 10th ACM conference on recommender systems*, pages 191–198,\n2016.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 373,
    "content": "[10] James Davidson, Benjamin Liebald, Junning Liu, Palash Nandy, Taylor Van Vleet, Ullas Gargi,\nSujoy Gupta, Yu He, Mike Lambert, Blake Livingston, et al. The youtube video recommendation\nsystem. In *Proceedings of the fourth ACM conference on Recommender systems*, pages 293–296,\n2010.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 374,
    "content": "[11] Yingpeng Du, Di Luo, Rui Yan, Xiaopei Wang, Hongzhi Liu, Hengshu Zhu, Yang Song, and Jie\nZhang. Enhancing job recommendation through llm-based generative adversarial networks. In\n*Proceedings of the AAAI Conference on Artificial Intelligence*, pages 8363–8371, 2024.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 375,
    "content": "[12] Wenqi Fan, Yao Ma, Dawei Yin, Jianping Wang, Jiliang Tang, and Qing Li. Deep social\ncollaborative filtering. In *Proceedings of the 13th ACM Conference on Recommender Systems*,\npages 305–313, 2019.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 376,
    "content": "[13] Wenqi Fan, Yao Ma, Qing Li, Jianping Wang, Guoyong Cai, Jiliang Tang, and Dawei Yin. A\ngraph neural network framework for social recommendations. *IEEE Transactions on Knowledge*\n*and Data Engineering*, 2020.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 377,
    "content": "[14] Wenqi Fan, Tyler Derr, Xiangyu Zhao, Yao Ma, Hui Liu, Jianping Wang, Jiliang Tang, and\nQing Li. Attacking black-box recommendations via copying cross-domain user profiles. In\n*2021 IEEE 37th International Conference on Data Engineering*, 2021.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 378,
    "content": "[15] Wenqi Fan, Yujuan Ding, Liangbo Ning, Shijie Wang, Hengyun Li, Dawei Yin, Tat-Seng Chua,\nand Qing Li. A survey on RAG meeting LLMs: Towards retrieval-augmented large language\nmodels. In *Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and*\n*Data Mining*, 2024.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 379,
    "content": "[16] Yunfan Gao, Yun Xiong, Xinyu Gao, Kangxiang Jia, Jinliu Pan, Yuxi Bi, Yi Dai, Jiawei Sun,\nand Haofen Wang. Retrieval-augmented generation for large language models: A survey. *arXiv*\n*preprint arXiv:2312.10997*, 2023.\n\n19\n\n\n-----",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 380,
    "content": "19\n\n\n-----\n\n[17] Jin Ge, Steve Sun, Joseph Owens, Victor Galvez, Oksana Gologorskaya, Jennifer C Lai, Mark J\nPletcher, and Ki Lai. Development of a liver disease-specific large language model chat interface\nusing retrieval augmented generation. *Hepatology*, 2024.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 381,
    "content": "[18] Shijie Geng, Shuchang Liu, Zuohui Fu, Yingqiang Ge, and Yongfeng Zhang. Recommendation\nas language processing (RLP): A unified pretrain, personalized prompt & predict paradigm (P5).\nIn *Proceedings of the 16th ACM Conference on Recommender Systems*, pages 299–315, 2022.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 382,
    "content": "[19] Ihsan Gunes, Cihan Kaleli, Alper Bilge, and Huseyin Polat. Shilling attacks against recommender systems: a comprehensive survey. *Artificial Intelligence Review*, 42:767–799, 2014.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 383,
    "content": "[20] F Maxwell Harper and Joseph A Konstan. The MovieLens datasets: History and context. *ACM*\n*Transactions on Interactive Intelligent Systems*, 2015.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 384,
    "content": "[21] Xiangnan He, Kuan Deng, Xiang Wang, Yan Li, Yongdong Zhang, and Meng Wang. Lightgcn:\nSimplifying and powering graph convolution network for recommendation. In *Proceedings of*\n*the 43rd International ACM SIGIR conference on research and development in Information*",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 385,
    "content": "*Retrieval*, pages 639–648, 2020.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 386,
    "content": "[22] Alec Helbling, Mansi Phute, Matthew Hull, and Duen Horng Chau. LLM self defense: By self\nexamination, LLMs know they are being tricked. *arXiv preprint arXiv:2308.07308*, 2023.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 387,
    "content": "[23] Neel Jain, Schwarzschild Avi, Yuxin Wen, Gowthami Somepalli, John Kirchenbauer, Ping-yeh\nChiang, Micah Goldblum, Aniruddha Saha, Jonas Geiping, and Tom Goldstein. Baseline defenses for adversarial attacks against aligned language models. *arXiv preprint arXiv:2309.00614*,\n2023.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 388,
    "content": "[24] Wei Jin, Haitao Mao, Zheng Li, Haoming Jiang, Chen Luo, Hongzhi Wen, Haoyu Han, Hanqing\nLu, Zhengyang Wang, Ruirui Li, et al. Amazon-M2: A multilingual multi-locale shopping\nsession dataset for recommendation and text generation. *Advances in Neural Information*\n*Processing Systems*, 2024.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 389,
    "content": "[25] Jacob Devlin Ming-Wei Chang Kenton and Lee Kristina Toutanova. BERT: Pre-training of\ndeep bidirectional transformers for language understanding. In *Proceedings of NAACL-HLT*,\npages 4171–4186, 2019.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 390,
    "content": "[26] John Kirchenbauer, Jonas Geiping, Yuxin Wen, Manli Shu, Khalid Saifullah, Kezhi Kong,\nKasun Fernando, Aniruddha Saha, Micah Goldblum, and Tom Goldstein. On the reliability of\nwatermarks for large language models. In *The Twelfth International Conference on Learning*\n*Representations*, 2023.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 391,
    "content": "[27] Louisa Lam and SY Suen. Application of majority voting to pattern recognition: an analysis of\nits behavior and performance. *IEEE Transactions on Systems, Man, and Cybernetics-Part A:*\n*Systems and Humans*, 27(5):553–568, 1997.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 392,
    "content": "[28] Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman\nGoyal, Heinrich Küttler, Mike Lewis, Wen-tau Yih, Tim Rocktäschel, et al. Retrieval-augmented\ngeneration for knowledge-intensive NLP tasks. *Advances in Neural Information Processing*\n*Systems*, 2020.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 393,
    "content": "[29] Huayang Li, Yixuan Su, Deng Cai, Yan Wang, and Lemao Liu. A survey on retrieval-augmented\ntext generation. *arXiv preprint arXiv:2202.01110*, 2022.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 394,
    "content": "[30] Linyang Li and Xipeng Qiu. Token-aware virtual adversarial training in natural language\nunderstanding. In *Proceedings of the AAAI Conference on Artificial Intelligence*, pages 8410–\n8418, 2021.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 395,
    "content": "[31] Linyang Li, Demin Song, and Xipeng Qiu. Text adversarial purification as defense against adversarial attacks. In *Proceedings of the 61st Annual Meeting of the Association for Computational*\n*Linguistics*, 2023.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 396,
    "content": "[32] Xiang Li, Zhenyu Li, Chen Shi, Yong Xu, Qing Du, Mingkui Tan, Jun Huang, and Wei Lin.\nAlphafin: Benchmarking financial analysis with retrieval-augmented stock-chain framework.\n*arXiv preprint arXiv:2403.12582*, 2024.\n\n20\n\n\n-----",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 397,
    "content": "20\n\n\n-----\n\n[33] Dawen Liang, Jaan Altosaar, Laurent Charlin, and David M Blei. Factorization meets the item\nembedding: Regularizing matrix factorization with item co-occurrence. In *Proceedings of the*\n*10th ACM conference on recommender systems*, pages 59–66, 2016.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 398,
    "content": "[34] Jiayi Liao, Sihang Li, Zhengyi Yang, Jiancan Wu, Yancheng Yuan, Xiang Wang, and Xiangnan\nHe. LLaRA: Large language-recommendation assistant. In *Proceedings of the 47th International*\n*ACM SIGIR Conference on Research and Development in Information Retrieval*, pages 1785–\n1795, 2024.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 399,
    "content": "[35] Jianghao Lin, Xinyi Dai, Yunjia Xi, Weiwen Liu, Bo Chen, Hao Zhang, Yong Liu, Chuhan Wu,\nXiangyang Li, Chenxu Zhu, et al. How can recommender systems benefit from large language\nmodels: A survey. *ACM Transactions on Information Systems*, 43(2):1–47, 2025.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 400,
    "content": "[36] Yujie Lin, Chenyang Wang, Zhumin Chen, Zhaochun Ren, Xin Xin, Qiang Yan, Maarten\nde Rijke, Xiuzhen Cheng, and Pengjie Ren. A self-correcting sequential recommender. In\n*Proceedings of the ACM Web Conference 2023*, pages 1283–1293, 2023.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 401,
    "content": "[37] Greg Linden, Brent Smith, and Jeremy York. Amazon. com recommendations: Item-to-item\ncollaborative filtering. *IEEE Internet computing*, 7(1):76–80, 2003.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 402,
    "content": "[38] Shang Liu, Zhenzhong Chen, Hongyi Liu, and Xinghai Hu. User-video co-attention network\nfor personalized micro-video recommendation. In *The world wide web conference*, pages\n3020–3026, 2019.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 403,
    "content": "[39] Xiaodong Liu, Hao Cheng, Pengcheng He, Weizhu Chen, Yu Wang, Hoifung Poon, and Jianfeng\nGao. Adversarial training for large neural language models. *arXiv preprint arXiv:2004.08994*,\n2020.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 404,
    "content": "[40] Yi Luo, Liang Rebecca Tang, Eojina Kim, and Xi Wang. Finding the reviews on yelp that\nactually matter to me: Innovative approach of improving recommender systems. *International*\n*Journal of Hospitality Management*, 91:102697, 2020.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 405,
    "content": "[41] Yuanjie Lyu, Zhiyu Li, Simin Niu, Feiyu Xiong, Bo Tang, Wenjin Wang, Hao Wu, Huanyong\nLiu, Tong Xu, and Enhong Chen. Crud-rag: A comprehensive chinese benchmark for retrievalaugmented generation of large language models. *ACM Transactions on Information Systems*,\n43(2):1–32, 2025.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 406,
    "content": "[42] Julian McAuley, Rahul Pandey, and Jure Leskovec. Inferring networks of substitutable and\ncomplementary products. In *Proceedings of the 21th ACM SIGKDD international conference*\n*on knowledge discovery and data mining*, pages 785–794, 2015.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 407,
    "content": "[43] Wenjie Mo, Jiashu Xu, Qin Liu, Jiongxiao Wang, Jun Yan, Chaowei Xiao, and Muhao Chen.\nTest-time backdoor mitigation for black-box large language models with defensive demonstrations. *arXiv preprint arXiv:2311.09763*, 2023.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 408,
    "content": "[44] Liangbo Ning, Ziran Liang, Zhuohang Jiang, Haohao Qu, Yujuan Ding, Wenqi Fan, Xiaoyong Wei, Shanru Lin, Hui Liu, Philip S. Yu, and Qing Li. A survey of webagents: Towards\nnext-generation ai agents for web automation with large foundation models. *arXiv preprint*\n*arXiv:2503.23350*, 2025.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 409,
    "content": "[45] Liang-bo Ning, Shijie Wang, Wenqi Fan, Qing Li, Xin Xu, Hao Chen, and Feiran Huang.\nCheatAgent: Attacking llm-empowered recommender systems via llm agent. In *ACM SIGKDD*\n*Conference on Knowledge Discovery and Data Mining*, pages 2284–2295, 2024.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 410,
    "content": "[46] Apurva Pathak, Kshitiz Gupta, and Julian McAuley. Generating and personalizing bundle\nrecommendations on steam. In *Proceedings of the 40th international ACM SIGIR conference*\n*on research and development in information retrieval*, pages 1073–1076, 2017.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 411,
    "content": "[47] Guilherme Penedo, Quentin Malartic, Daniel Hesslow, Ruxandra Cojocaru, Hamza Alobeidli,\nAlessandro Cappelli, Baptiste Pannier, Ebtesam Almazrouei, and Julien Launay. The refinedweb\ndataset for falcon llm: Outperforming curated corpora with web data only. *Advances in Neural*",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 412,
    "content": "*Information Processing Systems*, 2024.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 413,
    "content": "21\n\n\n-----\n\n[48] Andreas Pfadler, Huan Zhao, Jizhe Wang, Lifeng Wang, Pipei Huang, and Dik Lun Lee. Billionscale recommendation with heterogeneous side information at taobao. In *2020 IEEE 36th*\n*International Conference on Data Engineering (ICDE)*, pages 1667–1676. IEEE, 2020.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 414,
    "content": "[49] Ivan Provilkov, Dmitrii Emelianenko, and Elena Voita. BPE-dropout: Simple and effective\nsubword regularization. In *Proceedings of the 58th Annual Meeting of the Association for*\n*Computational Linguistics*, pages 1882–1892, Online, 2020. Association for Computational\nLinguistics.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 415,
    "content": "[50] Haohao Qu, Wenqi Fan, Zihuai Zhao, and Qing Li. TokenRec: Learning to tokenize id for\nllm-based generative recommendation. *arXiv preprint arXiv:2406.10450*, 2024.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 416,
    "content": "[51] Haohao Qu, Liangbo Ning, Rui An, Wenqi Fan, Tyler Derr, Xin Xu, and Qing Li. A survey of\nmamba. *arXiv preprint arXiv:2408.01129*, 2024.\n\n[52] Vipula Rawte, Amit Sheth, and Amitava Das. A survey of hallucination in large foundation\nmodels. *arXiv preprint arXiv:2309.05922*, 2023.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 417,
    "content": "[53] Yankun Ren, Zhongde Chen, Xinxing Yang, Longfei Li, Cong Jiang, Lei Cheng, Bo Zhang,\nLinjian Mo, and Jun Zhou. Enhancing sequential recommenders with augmented knowledge\nfrom aligned large language models. In *Proceedings of the 47th International ACM SIGIR*",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 418,
    "content": "*Conference on Research and Development in Information Retrieval*, 2024.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 419,
    "content": "[54] Mingdan Si and Qingshan Li. Shilling attacks against collaborative recommender systems: a\nreview. *Artificial Intelligence Review*, 53:291–319, 2020.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 420,
    "content": "[55] Changxin Tian, Yuexiang Xie, Yaliang Li, Nan Yang, and Wayne Xin Zhao. Learning to denoise\nunreliable interactions for graph collaborative filtering. In *Proceedings of the 45th international*\n*ACM SIGIR conference on research and development in information retrieval*, pages 122–132,\n2022.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 421,
    "content": "[56] Neeraj Varshney, Pavel Dolin, Agastya Seth, and Chitta Baral. The art of defending: A\nsystematic evaluation and analysis of LLM defense strategies on safety and over-defensiveness.\nIn *Findings of the Association for Computational Linguistics ACL 2024*, 2024.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 422,
    "content": "[57] Maxim Kuznetsov Vladimir Vorobev. A paraphrasing model based on chatgpt paraphrases.\n2023.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 423,
    "content": "[58] Bohao Wang, Feng Liu, Changwang Zhang, Jiawei Chen, Yudi Wu, Sheng Zhou, Xingyu Lou,\nJun Wang, Yan Feng, Chun Chen, et al. Llm4dsr: Leveraing large language model for denoising\nsequential recommendation. *arXiv preprint arXiv:2408.08208*, 2024.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 424,
    "content": "[59] Dilin Wang, Chengyue Gong, and Qiang Liu. Improving neural language modeling via adversarial training. In *International Conference on Machine Learning*, pages 6555–6565. PMLR,\n2019.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 425,
    "content": "[60] Wenjie Wang, Fuli Feng, Xiangnan He, Liqiang Nie, and Tat-Seng Chua. Denoising implicit\nfeedback for recommendation. In *Proceedings of the 14th ACM international conference on*\n*web search and data mining*, pages 373–381, 2021.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 426,
    "content": "[61] Wenjie Wang, Fuli Feng, Xiangnan He, Hanwang Zhang, and Tat-Seng Chua. Clicks can be\ncheating: Counterfactual recommendation for mitigating clickbait issue. In *International ACM*\n*SIGIR Conference on Research and Development in Information Retrieval*, pages 1288–1297,\n2021.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 427,
    "content": "[62] Xin Wang, Hong Chen, Zirui Pan, Yuwei Zhou, Chaoyu Guan, Lifeng Sun, and Wenwu\nZhu. Automated disentangled sequential recommendation with large language models. *ACM*\n*Transactions on Information Systems*, 43(2):1–29, 2025.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 428,
    "content": "[63] Zhaoyang Wang, Zhiyue Liu, Xiaopeng Zheng, Qinliang Su, and Jiahai Wang. Rmlm: A flexible\ndefense framework for proactively mitigating word-level adversarial attacks. In *Proceedings of*\n*the 61st Annual Meeting of the Association for Computational Linguistics*, pages 2757–2774,\n2023.\n\n22",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 429,
    "content": "22\n\n\n-----\n\n[64] Yinwei Wei, Xiang Wang, Qi Li, Liqiang Nie, Yan Li, Xuanping Li, and Tat-Seng Chua. Contrastive learning for cold-start recommendation. In *Proceedings of the 29th ACM International*\n*Conference on Multimedia*, pages 5382–5390, 2021.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 430,
    "content": "[65] Zeming Wei, Yifei Wang, and Yisen Wang. Jailbreak and guard aligned language models with\nonly few in-context demonstrations. *arXiv preprint arXiv:2310.06387*, 2023.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 431,
    "content": "[66] Guillaume Wenzek, Marie-Anne Lachaux, Alexis Conneau, Vishrav Chaudhary, Francisco\nGuzmán, Armand Joulin, and Édouard Grave. Ccnet: Extracting high quality monolingual\ndatasets from web crawl data. In *Proceedings of the Twelfth Language Resources and Evaluation*",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 432,
    "content": "*Conference*, pages 4003–4012, 2020.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 433,
    "content": "[67] Sophie Xhonneux, Alessandro Sordoni, Stephan Günnemann, Gauthier Gidel, and Leo Schwinn.\nEfficient adversarial training in llms with continuous attacks. *arXiv preprint arXiv:2405.15589*,\n2024.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 434,
    "content": "[68] Shuyuan Xu, Wenyue Hua, and Yongfeng Zhang. OpenP5: An open-source platform for\ndeveloping, training, and evaluating llm-based recommender systems. *SIGIR*, 2024.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 435,
    "content": "[69] Xilie Xu, Keyi Kong, Ning Liu, Lizhen Cui, Di Wang, Jingfeng Zhang, and Mohan Kankanhalli.\nAn LLM can fool itself: A prompt-based adversarial attack. In *The Twelfth International*\n*Conference on Learning Representations* .",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 436,
    "content": "[70] Yifan Yao, Jinhao Duan, Kaidi Xu, Yuanfang Cai, Zhibo Sun, and Yue Zhang. A survey on large\nlanguage model (LLM) security and privacy: The good, the bad, and the ugly. *High-Confidence*\n*Computing*, 2024.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 437,
    "content": "[71] Antonio Jimeno Yepes, Yao You, Jan Milczek, Sebastian Laverde, and Leah Li. Financial report\nchunking for effective retrieval augmented generation. *arXiv preprint arXiv:2402.05131*, 2024.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 438,
    "content": "[72] Yisong Yue, Rajan Patel, and Hein Roehrig. Beyond position bias: Examining result attractiveness as a source of presentation bias in clickthrough data. In *Proceedings of the 19th*\n*international conference on World wide web*, pages 1011–1018, 2010.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 439,
    "content": "[73] Kaike Zhang, Qi Cao, Yunfan Wu, Fei Sun, Huawei Shen, and Xueqi Cheng. Lorec: Combating\npoisons with large language model for robust sequential recommendation. In *Proceedings of*\n*the 47th International ACM SIGIR Conference on Research and Development in Information*",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 440,
    "content": "*Retrieval*, pages 1733–1742, 2024.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 441,
    "content": "[74] Liang Zhang, Guannan Liu, Xiaohui Liu, and Junjie Wu. Denoising item graph with disentangled\nlearning for recommendation. *IEEE Transactions on Knowledge and Data Engineering*, 2024.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 442,
    "content": "[75] Shijie Zhang, Hongzhi Yin, Tong Chen, Quoc Viet Nguyen Hung, Zi Huang, and Lizhen\nCui. Gcn-based user representation learning for unifying robust recommendation and fraudster\ndetection. In *Proceedings of the 43rd international ACM SIGIR conference on research and*",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 443,
    "content": "*development in information retrieval*, pages 689–698, 2020.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 444,
    "content": "[76] Zhen Zhang, Guanhua Zhang, Bairu Hou, Wenqi Fan, Qing Li, Sijia Liu, Yang Zhang, and\nShiyu Chang. Certified robustness for large language models with self-denoising. *arXiv preprint*\n*arXiv:2307.07171*, 2023.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 445,
    "content": "[77] Zihuai Zhao, Wenqi Fan, Jiatong Li, Yunqing Liu, Xiaowei Mei, Yiqi Wang, Zhen Wen, Fei\nWang, Xiangyu Zhao, Jiliang Tang, et al. Recommender systems in the era of large language\nmodels. *IEEE Transactions on Knowledge and Data Engineering*, 2024.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 446,
    "content": "[78] Bowen Zheng, Yupeng Hou, Hongyu Lu, Yu Chen, Wayne Xin Zhao, Ming Chen, and Ji-Rong\nWen. Adapting large language models by integrating collaborative semantics for recommendation. In *2024 IEEE 40th International Conference on Data Engineering (ICDE)*, pages\n1435–1448. IEEE, 2024.",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  },
  {
    "chunk_id": 447,
    "content": "[79] Han Zhu, Xiang Li, Pengye Zhang, Guozheng Li, Jie He, Han Li, and Kun Gai. Learning\ntree-based deep model for recommender systems. In *Proceedings of the 24th ACM SIGKDD*\n*International Conference on Knowledge Discovery & Data Mining*, 2018.\n\n23\n\n\n-----",
    "metadata": {
      "source": "2504.02458v1.md"
    }
  }
]